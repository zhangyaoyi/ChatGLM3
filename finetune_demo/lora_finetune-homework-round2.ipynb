{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "id": "89b89f64d8f8053d",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB及以上（推荐使用30系或A10等sm80架构以上的NVIDIA显卡进行尝试）\n",
    "内存：16GB\n",
    "RAM: 2.9 /16 GB\n",
    "GPU RAM: 15.5/16.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "id": "a7bd9a514ed09ea6",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 0. 环境检查\n",
    "首先，先检查代码的运行地址，确保运行地址处于 `finetune_demo` 中。\n",
    "并且，确保已经安装了 `requirements.txt`中的依赖。\n",
    "\n",
    "> 本 demo 中，不需要使用 deepspeed, mpi4py 两个依赖，如果您安装这两个依赖遇到问题，可以不安装这两个依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7703109d1443346",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/Workspace/ChatGLM3/finetune_demo\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50e92810011977",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "cellView": "form",
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "id": "a1b7a99923349056",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c87410a24d844f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17c87410a24d844f",
    "outputId": "e347fc7d-875e-40c9-c682-3e064100476b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:03<00:00,  1.85it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.0312\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 114599 examples [00:00, 1390855.71 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
      "Generating validation split: 1070 examples [00:00, 790124.17 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
      "Generating test split: 1070 examples [00:00, 854839.10 examples/s]\n",
      "Map (num_proc=16): 100%|█████| 114599/114599 [00:01<00:00, 102942.44 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 3184.80 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 3232.54 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34,380\n",
      "  Number of trainable parameters = 1,949,696\n",
      "{'loss': 4.0969, 'grad_norm': 3.1475279331207275, 'learning_rate': 4.985456660849331e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6415, 'grad_norm': 4.6406989097595215, 'learning_rate': 4.970913321698662e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5582, 'grad_norm': 5.00098180770874, 'learning_rate': 4.956369982547993e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5426, 'grad_norm': 5.286025047302246, 'learning_rate': 4.9418266433973246e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5089, 'grad_norm': 5.8512187004089355, 'learning_rate': 4.9272833042466556e-05, 'epoch': 0.02}\n",
      "  1%|▌                                    | 500/34380 [05:12<5:19:50,  1.77it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.14s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.61s/it]\u001B[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.92s/it]\u001B[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.244 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001B[A{'eval_rouge-1': 30.545274, 'eval_rouge-2': 6.493294, 'eval_rouge-l': 23.984523999999997, 'eval_bleu-4': 0.031397846321602904, 'eval_runtime': 25.6535, 'eval_samples_per_second': 1.949, 'eval_steps_per_second': 0.156, 'epoch': 0.02}\n",
      "  1%|▌                                    | 500/34380 [05:37<5:19:50,  1.77it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.92s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4774, 'grad_norm': 5.70848274230957, 'learning_rate': 4.912739965095986e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4719, 'grad_norm': 5.743645668029785, 'learning_rate': 4.898196625945317e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4631, 'grad_norm': 7.316584587097168, 'learning_rate': 4.883653286794648e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4778, 'grad_norm': 6.864858627319336, 'learning_rate': 4.869109947643979e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4096, 'grad_norm': 6.5802178382873535, 'learning_rate': 4.85456660849331e-05, 'epoch': 0.04}\n",
      "  3%|█                                   | 1000/34380 [10:45<5:52:13,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.03s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.30s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.90562, 'eval_rouge-2': 6.414097999999999, 'eval_rouge-l': 23.438138, 'eval_bleu-4': 0.03117460945352759, 'eval_runtime': 17.3155, 'eval_samples_per_second': 2.888, 'eval_steps_per_second': 0.231, 'epoch': 0.04}\n",
      "  3%|█                                   | 1000/34380 [11:02<5:52:13,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.26s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-1000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4264, 'grad_norm': 6.227141857147217, 'learning_rate': 4.8400232693426414e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4006, 'grad_norm': 6.177114009857178, 'learning_rate': 4.8254799301919725e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4497, 'grad_norm': 7.891374588012695, 'learning_rate': 4.8109365910413036e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4457, 'grad_norm': 6.691070556640625, 'learning_rate': 4.796393251890634e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4231, 'grad_norm': 6.115077972412109, 'learning_rate': 4.781849912739965e-05, 'epoch': 0.07}\n",
      "  4%|█▌                                  | 1500/34380 [16:12<5:55:55,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.432631999999998, 'eval_rouge-2': 6.519931999999999, 'eval_rouge-l': 22.736814, 'eval_bleu-4': 0.03160316912579842, 'eval_runtime': 37.8984, 'eval_samples_per_second': 1.319, 'eval_steps_per_second': 0.106, 'epoch': 0.07}\n",
      "  4%|█▌                                  | 1500/34380 [16:49<5:55:55,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.88s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-1500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4085, 'grad_norm': 6.859813690185547, 'learning_rate': 4.767306573589296e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4492, 'grad_norm': 6.923884391784668, 'learning_rate': 4.752763234438627e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4237, 'grad_norm': 6.979555130004883, 'learning_rate': 4.738219895287958e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3863, 'grad_norm': 6.705827713012695, 'learning_rate': 4.7236765561372894e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3951, 'grad_norm': 7.7864460945129395, 'learning_rate': 4.7091332169866205e-05, 'epoch': 0.09}\n",
      "  6%|██                                  | 2000/34380 [21:57<5:50:46,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:23<00:08,  8.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.499977999999995, 'eval_rouge-2': 6.776058000000001, 'eval_rouge-l': 23.491566000000002, 'eval_bleu-4': 0.03159466258619369, 'eval_runtime': 45.4934, 'eval_samples_per_second': 1.099, 'eval_steps_per_second': 0.088, 'epoch': 0.09}\n",
      "  6%|██                                  | 2000/34380 [22:43<5:50:46,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:33<00:00,  8.72s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-2000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4177, 'grad_norm': 6.48070764541626, 'learning_rate': 4.6945898778359516e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4235, 'grad_norm': 7.2512969970703125, 'learning_rate': 4.680046538685282e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3901, 'grad_norm': 7.840146541595459, 'learning_rate': 4.665503199534613e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3685, 'grad_norm': 6.393359661102295, 'learning_rate': 4.650959860383944e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3892, 'grad_norm': 6.363565921783447, 'learning_rate': 4.636416521233275e-05, 'epoch': 0.11}\n",
      "  7%|██▌                                 | 2500/34380 [27:48<5:55:42,  1.49it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.09s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.58s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.322537999999998, 'eval_rouge-2': 7.010930000000001, 'eval_rouge-l': 24.550649999999997, 'eval_bleu-4': 0.033941990455113806, 'eval_runtime': 17.6188, 'eval_samples_per_second': 2.838, 'eval_steps_per_second': 0.227, 'epoch': 0.11}\n",
      "  7%|██▌                                 | 2500/34380 [28:05<5:55:42,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.11s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-2500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4032, 'grad_norm': 7.7735395431518555, 'learning_rate': 4.621873182082606e-05, 'epoch': 0.11}\n",
      "{'loss': 3.378, 'grad_norm': 6.510788440704346, 'learning_rate': 4.6073298429319374e-05, 'epoch': 0.12}\n",
      "{'loss': 3.345, 'grad_norm': 7.00177001953125, 'learning_rate': 4.5927865037812685e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3518, 'grad_norm': 7.758155345916748, 'learning_rate': 4.5782431646305995e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3423, 'grad_norm': 6.896430492401123, 'learning_rate': 4.56369982547993e-05, 'epoch': 0.13}\n",
      "  9%|███▏                                | 3000/34380 [33:12<5:24:02,  1.61it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.25s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.68s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.780934000000002, 'eval_rouge-2': 6.548525999999999, 'eval_rouge-l': 23.960131999999998, 'eval_bleu-4': 0.033512260467862175, 'eval_runtime': 35.8926, 'eval_samples_per_second': 1.393, 'eval_steps_per_second': 0.111, 'epoch': 0.13}\n",
      "  9%|███▏                                | 3000/34380 [33:48<5:24:02,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.96s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-3000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3538, 'grad_norm': 7.053001403808594, 'learning_rate': 4.549156486329261e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4107, 'grad_norm': 7.885371685028076, 'learning_rate': 4.534613147178592e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3564, 'grad_norm': 7.558918476104736, 'learning_rate': 4.520069808027924e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3812, 'grad_norm': 6.6915717124938965, 'learning_rate': 4.505526468877254e-05, 'epoch': 0.15}\n",
      "{'loss': 3.3216, 'grad_norm': 6.962491512298584, 'learning_rate': 4.490983129726585e-05, 'epoch': 0.15}\n",
      " 10%|███▋                                | 3500/34380 [38:57<5:24:49,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.01it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.447048, 'eval_rouge-2': 7.379569999999998, 'eval_rouge-l': 25.694214, 'eval_bleu-4': 0.03759904625578144, 'eval_runtime': 8.058, 'eval_samples_per_second': 6.205, 'eval_steps_per_second': 0.496, 'epoch': 0.15}\n",
      " 10%|███▋                                | 3500/34380 [39:05<5:24:49,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-3500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3385, 'grad_norm': 7.182916164398193, 'learning_rate': 4.4764397905759164e-05, 'epoch': 0.16}\n",
      "{'loss': 3.3413, 'grad_norm': 6.399035930633545, 'learning_rate': 4.4618964514252475e-05, 'epoch': 0.16}\n",
      "{'loss': 3.4127, 'grad_norm': 7.515894412994385, 'learning_rate': 4.447353112274578e-05, 'epoch': 0.17}\n",
      "{'loss': 3.3393, 'grad_norm': 7.04632568359375, 'learning_rate': 4.4328097731239097e-05, 'epoch': 0.17}\n",
      "{'loss': 3.3296, 'grad_norm': 7.053627967834473, 'learning_rate': 4.418266433973241e-05, 'epoch': 0.17}\n",
      " 12%|████▏                               | 4000/34380 [44:12<4:58:51,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.40091, 'eval_rouge-2': 6.721768, 'eval_rouge-l': 23.909319999999997, 'eval_bleu-4': 0.03180415165858326, 'eval_runtime': 27.6239, 'eval_samples_per_second': 1.81, 'eval_steps_per_second': 0.145, 'epoch': 0.17}\n",
      " 12%|████▏                               | 4000/34380 [44:40<4:58:51,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.93s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-4000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.358, 'grad_norm': 7.17117166519165, 'learning_rate': 4.403723094822572e-05, 'epoch': 0.18}\n",
      "{'loss': 3.3457, 'grad_norm': 6.6608357429504395, 'learning_rate': 4.389179755671902e-05, 'epoch': 0.18}\n",
      "{'loss': 3.2569, 'grad_norm': 7.140801906585693, 'learning_rate': 4.374636416521233e-05, 'epoch': 0.19}\n",
      "{'loss': 3.3231, 'grad_norm': 7.303428649902344, 'learning_rate': 4.3600930773705644e-05, 'epoch': 0.19}\n",
      "{'loss': 3.33, 'grad_norm': 7.528174877166748, 'learning_rate': 4.3455497382198955e-05, 'epoch': 0.2}\n",
      " 13%|████▋                               | 4500/34380 [49:49<5:10:47,  1.60it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.22s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.56832, 'eval_rouge-2': 7.620704000000001, 'eval_rouge-l': 24.859274000000006, 'eval_bleu-4': 0.03435977717681832, 'eval_runtime': 27.1482, 'eval_samples_per_second': 1.842, 'eval_steps_per_second': 0.147, 'epoch': 0.2}\n",
      " 13%|████▋                               | 4500/34380 [50:17<5:10:47,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.01s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-4500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3684, 'grad_norm': 8.099676132202148, 'learning_rate': 4.3310063990692265e-05, 'epoch': 0.2}\n",
      "{'loss': 3.2939, 'grad_norm': 7.195583343505859, 'learning_rate': 4.3164630599185576e-05, 'epoch': 0.21}\n",
      "{'loss': 3.3848, 'grad_norm': 7.436572074890137, 'learning_rate': 4.301919720767889e-05, 'epoch': 0.21}\n",
      "{'loss': 3.303, 'grad_norm': 6.863331317901611, 'learning_rate': 4.28737638161722e-05, 'epoch': 0.21}\n",
      "{'loss': 3.3204, 'grad_norm': 7.849661350250244, 'learning_rate': 4.27283304246655e-05, 'epoch': 0.22}\n",
      " 15%|█████▏                              | 5000/34380 [55:29<5:13:35,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.32s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.71s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.89526, 'eval_rouge-2': 7.302969999999999, 'eval_rouge-l': 25.502540000000003, 'eval_bleu-4': 0.03508118143815924, 'eval_runtime': 18.8049, 'eval_samples_per_second': 2.659, 'eval_steps_per_second': 0.213, 'epoch': 0.22}\n",
      " 15%|█████▏                              | 5000/34380 [55:48<5:13:35,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.94s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-5000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3557, 'grad_norm': 8.059579849243164, 'learning_rate': 4.258289703315881e-05, 'epoch': 0.22}\n",
      "{'loss': 3.3647, 'grad_norm': 7.411378383636475, 'learning_rate': 4.2437463641652123e-05, 'epoch': 0.23}\n",
      "{'loss': 3.3218, 'grad_norm': 7.71036434173584, 'learning_rate': 4.2292030250145434e-05, 'epoch': 0.23}\n",
      "{'loss': 3.3068, 'grad_norm': 8.015463829040527, 'learning_rate': 4.2146596858638745e-05, 'epoch': 0.24}\n",
      "{'loss': 3.3307, 'grad_norm': 7.3191819190979, 'learning_rate': 4.2001163467132056e-05, 'epoch': 0.24}\n",
      " 16%|█████▍                            | 5500/34380 [1:00:56<5:01:18,  1.60it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.41s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.46s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.48360399999999, 'eval_rouge-2': 7.30302, 'eval_rouge-l': 25.980156, 'eval_bleu-4': 0.036502590508074334, 'eval_runtime': 17.908, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.223, 'epoch': 0.24}\n",
      " 16%|█████▍                            | 5500/34380 [1:01:14<5:01:18,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-5500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.306, 'grad_norm': 6.805530548095703, 'learning_rate': 4.185573007562537e-05, 'epoch': 0.24}\n",
      "{'loss': 3.3247, 'grad_norm': 7.566136360168457, 'learning_rate': 4.171029668411868e-05, 'epoch': 0.25}\n",
      "{'loss': 3.2988, 'grad_norm': 7.157711505889893, 'learning_rate': 4.156486329261198e-05, 'epoch': 0.25}\n",
      "{'loss': 3.3133, 'grad_norm': 7.907533168792725, 'learning_rate': 4.141942990110529e-05, 'epoch': 0.26}\n",
      "{'loss': 3.2656, 'grad_norm': 7.6947455406188965, 'learning_rate': 4.12739965095986e-05, 'epoch': 0.26}\n",
      " 17%|█████▉                            | 6000/34380 [1:06:20<4:26:19,  1.78it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.09it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:05,  5.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.632667999999995, 'eval_rouge-2': 7.359028, 'eval_rouge-l': 25.510628, 'eval_bleu-4': 0.034258843271828765, 'eval_runtime': 26.9445, 'eval_samples_per_second': 1.856, 'eval_steps_per_second': 0.148, 'epoch': 0.26}\n",
      " 17%|█████▉                            | 6000/34380 [1:06:47<4:26:19,  1.78it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.76s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-6000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3345, 'grad_norm': 9.086990356445312, 'learning_rate': 4.112856311809192e-05, 'epoch': 0.27}\n",
      "{'loss': 3.3162, 'grad_norm': 7.312833786010742, 'learning_rate': 4.0983129726585225e-05, 'epoch': 0.27}\n",
      "{'loss': 3.3034, 'grad_norm': 7.286571979522705, 'learning_rate': 4.0837696335078535e-05, 'epoch': 0.27}\n",
      "{'loss': 3.2951, 'grad_norm': 7.498257637023926, 'learning_rate': 4.0692262943571846e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2807, 'grad_norm': 7.071794509887695, 'learning_rate': 4.054682955206516e-05, 'epoch': 0.28}\n",
      " 19%|██████▍                           | 6500/34380 [1:11:56<5:09:44,  1.50it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.18s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.293749999999996, 'eval_rouge-2': 7.713886, 'eval_rouge-l': 25.289742, 'eval_bleu-4': 0.038822357001102294, 'eval_runtime': 17.2534, 'eval_samples_per_second': 2.898, 'eval_steps_per_second': 0.232, 'epoch': 0.28}\n",
      " 19%|██████▍                           | 6500/34380 [1:12:13<5:09:44,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  2.98s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-6500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3177, 'grad_norm': 7.700517654418945, 'learning_rate': 4.040139616055846e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2952, 'grad_norm': 8.31343936920166, 'learning_rate': 4.025596276905177e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2717, 'grad_norm': 7.088015556335449, 'learning_rate': 4.011052937754509e-05, 'epoch': 0.3}\n",
      "{'loss': 3.302, 'grad_norm': 7.2497382164001465, 'learning_rate': 3.99650959860384e-05, 'epoch': 0.3}\n",
      "{'loss': 3.3109, 'grad_norm': 7.947322368621826, 'learning_rate': 3.9819662594531704e-05, 'epoch': 0.31}\n",
      " 20%|██████▉                           | 7000/34380 [1:17:22<5:09:18,  1.48it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:15<00:04,  4.80s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.079766, 'eval_rouge-2': 7.649658, 'eval_rouge-l': 24.71808800000001, 'eval_bleu-4': 0.036443868166969734, 'eval_runtime': 28.95, 'eval_samples_per_second': 1.727, 'eval_steps_per_second': 0.138, 'epoch': 0.31}\n",
      " 20%|██████▉                           | 7000/34380 [1:17:51<5:09:18,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  3.54s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-7000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2931, 'grad_norm': 6.875996112823486, 'learning_rate': 3.9674229203025015e-05, 'epoch': 0.31}\n",
      "{'loss': 3.3073, 'grad_norm': 7.979851245880127, 'learning_rate': 3.9528795811518326e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2831, 'grad_norm': 6.9280219078063965, 'learning_rate': 3.938336242001164e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2536, 'grad_norm': 8.161873817443848, 'learning_rate': 3.923792902850494e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2836, 'grad_norm': 8.608377456665039, 'learning_rate': 3.909249563699826e-05, 'epoch': 0.33}\n",
      " 22%|███████▍                          | 7500/34380 [1:22:59<4:37:39,  1.61it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.43s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.947348, 'eval_rouge-2': 7.437066, 'eval_rouge-l': 23.797674, 'eval_bleu-4': 0.03613610457898476, 'eval_runtime': 27.763, 'eval_samples_per_second': 1.801, 'eval_steps_per_second': 0.144, 'epoch': 0.33}\n",
      " 22%|███████▍                          | 7500/34380 [1:23:26<4:37:39,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.18s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-7500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2393, 'grad_norm': 7.2424397468566895, 'learning_rate': 3.894706224549157e-05, 'epoch': 0.33}\n",
      "{'loss': 3.2987, 'grad_norm': 7.478527545928955, 'learning_rate': 3.880162885398488e-05, 'epoch': 0.34}\n",
      "{'loss': 3.3296, 'grad_norm': 8.44472885131836, 'learning_rate': 3.8656195462478184e-05, 'epoch': 0.34}\n",
      "{'loss': 3.24, 'grad_norm': 7.994296073913574, 'learning_rate': 3.8510762070971495e-05, 'epoch': 0.34}\n",
      "{'loss': 3.2657, 'grad_norm': 7.241217136383057, 'learning_rate': 3.8365328679464806e-05, 'epoch': 0.35}\n",
      " 23%|███████▉                          | 8000/34380 [1:28:34<4:37:40,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.67s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.339976, 'eval_rouge-2': 8.575411999999998, 'eval_rouge-l': 26.102021999999998, 'eval_bleu-4': 0.04083976196766155, 'eval_runtime': 17.4604, 'eval_samples_per_second': 2.864, 'eval_steps_per_second': 0.229, 'epoch': 0.35}\n",
      " 23%|███████▉                          | 8000/34380 [1:28:52<4:37:40,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.00s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-8000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2734, 'grad_norm': 6.688027858734131, 'learning_rate': 3.8219895287958116e-05, 'epoch': 0.35}\n",
      "{'loss': 3.2827, 'grad_norm': 8.485016822814941, 'learning_rate': 3.807446189645143e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2957, 'grad_norm': 7.331892013549805, 'learning_rate': 3.792902850494474e-05, 'epoch': 0.36}\n",
      "{'loss': 3.269, 'grad_norm': 7.471316814422607, 'learning_rate': 3.778359511343805e-05, 'epoch': 0.37}\n",
      "{'loss': 3.2516, 'grad_norm': 8.299535751342773, 'learning_rate': 3.763816172193136e-05, 'epoch': 0.37}\n",
      " 25%|████████▍                         | 8500/34380 [1:33:58<4:10:11,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:23<00:08,  8.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.017022000000004, 'eval_rouge-2': 7.303442, 'eval_rouge-l': 25.373492000000002, 'eval_bleu-4': 0.03704850191875588, 'eval_runtime': 27.9126, 'eval_samples_per_second': 1.791, 'eval_steps_per_second': 0.143, 'epoch': 0.37}\n",
      " 25%|████████▍                         | 8500/34380 [1:34:26<4:10:11,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.74s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-8500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2428, 'grad_norm': 14.002510070800781, 'learning_rate': 3.7492728330424664e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2819, 'grad_norm': 8.786118507385254, 'learning_rate': 3.7347294938917974e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2385, 'grad_norm': 8.338224411010742, 'learning_rate': 3.7201861547411285e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2796, 'grad_norm': 7.6726908683776855, 'learning_rate': 3.7056428155904596e-05, 'epoch': 0.39}\n",
      "{'loss': 3.2467, 'grad_norm': 8.076858520507812, 'learning_rate': 3.691099476439791e-05, 'epoch': 0.39}\n",
      " 26%|████████▉                         | 9000/34380 [1:39:33<4:03:30,  1.74it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.41s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.627082, 'eval_rouge-2': 8.071512, 'eval_rouge-l': 24.953972, 'eval_bleu-4': 0.03904751099834435, 'eval_runtime': 27.8464, 'eval_samples_per_second': 1.796, 'eval_steps_per_second': 0.144, 'epoch': 0.39}\n",
      " 26%|████████▉                         | 9000/34380 [1:40:01<4:03:30,  1.74it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.22s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-9000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2495, 'grad_norm': 8.192225456237793, 'learning_rate': 3.676556137289122e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2522, 'grad_norm': 7.740852355957031, 'learning_rate': 3.662012798138453e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2995, 'grad_norm': 7.210042476654053, 'learning_rate': 3.647469458987784e-05, 'epoch': 0.41}\n",
      "{'loss': 3.2263, 'grad_norm': 7.048435211181641, 'learning_rate': 3.632926119837114e-05, 'epoch': 0.41}\n",
      "{'loss': 3.2644, 'grad_norm': 8.926847457885742, 'learning_rate': 3.6183827806864454e-05, 'epoch': 0.41}\n",
      " 28%|█████████▍                        | 9500/34380 [1:45:08<4:04:31,  1.70it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.35s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.252852000000004, 'eval_rouge-2': 8.014166000000001, 'eval_rouge-l': 25.817768, 'eval_bleu-4': 0.03765545457589648, 'eval_runtime': 17.1249, 'eval_samples_per_second': 2.92, 'eval_steps_per_second': 0.234, 'epoch': 0.41}\n",
      " 28%|█████████▍                        | 9500/34380 [1:45:25<4:04:31,  1.70it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.14s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-9500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.227, 'grad_norm': 9.03271484375, 'learning_rate': 3.6038394415357765e-05, 'epoch': 0.42}\n",
      "{'loss': 3.2168, 'grad_norm': 7.403310298919678, 'learning_rate': 3.589296102385108e-05, 'epoch': 0.42}\n",
      "{'loss': 3.2281, 'grad_norm': 7.414134979248047, 'learning_rate': 3.5747527632344386e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2615, 'grad_norm': 8.332907676696777, 'learning_rate': 3.56020942408377e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2522, 'grad_norm': 7.91865873336792, 'learning_rate': 3.545666084933101e-05, 'epoch': 0.44}\n",
      " 29%|█████████▌                       | 10000/34380 [1:50:33<3:59:32,  1.70it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.26s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.19289, 'eval_rouge-2': 7.7551559999999995, 'eval_rouge-l': 25.360284, 'eval_bleu-4': 0.038967221484228085, 'eval_runtime': 8.1362, 'eval_samples_per_second': 6.145, 'eval_steps_per_second': 0.492, 'epoch': 0.44}\n",
      " 29%|█████████▌                       | 10000/34380 [1:50:41<3:59:32,  1.70it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.32s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-10000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2278, 'grad_norm': 8.02910041809082, 'learning_rate': 3.531122745782432e-05, 'epoch': 0.44}\n",
      "{'loss': 3.2326, 'grad_norm': 8.47148323059082, 'learning_rate': 3.516579406631762e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2372, 'grad_norm': 7.8877644538879395, 'learning_rate': 3.5020360674810934e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2173, 'grad_norm': 8.136540412902832, 'learning_rate': 3.487492728330425e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2204, 'grad_norm': 7.809272289276123, 'learning_rate': 3.472949389179756e-05, 'epoch': 0.46}\n",
      " 31%|██████████                       | 10500/34380 [1:55:49<4:03:44,  1.63it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.28s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.716794, 'eval_rouge-2': 8.246263999999998, 'eval_rouge-l': 25.612718000000005, 'eval_bleu-4': 0.04118469086220514, 'eval_runtime': 17.3887, 'eval_samples_per_second': 2.875, 'eval_steps_per_second': 0.23, 'epoch': 0.46}\n",
      " 31%|██████████                       | 10500/34380 [1:56:06<4:03:44,  1.63it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-10500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2556, 'grad_norm': 7.687073707580566, 'learning_rate': 3.4584060500290866e-05, 'epoch': 0.46}\n",
      "{'loss': 3.2452, 'grad_norm': 7.656728267669678, 'learning_rate': 3.443862710878418e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2481, 'grad_norm': 8.15871810913086, 'learning_rate': 3.429319371727749e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2369, 'grad_norm': 7.223443984985352, 'learning_rate': 3.41477603257708e-05, 'epoch': 0.48}\n",
      "{'loss': 3.2404, 'grad_norm': 7.354916572570801, 'learning_rate': 3.400232693426411e-05, 'epoch': 0.48}\n",
      " 32%|██████████▌                      | 11000/34380 [2:01:16<3:52:54,  1.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.160562, 'eval_rouge-2': 7.365448, 'eval_rouge-l': 24.249769999999998, 'eval_bleu-4': 0.034532880209735925, 'eval_runtime': 45.523, 'eval_samples_per_second': 1.098, 'eval_steps_per_second': 0.088, 'epoch': 0.48}\n",
      " 32%|██████████▌                      | 11000/34380 [2:02:01<3:52:54,  1.67it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:33<00:00,  8.72s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-11000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2192, 'grad_norm': 7.897989749908447, 'learning_rate': 3.385689354275742e-05, 'epoch': 0.48}\n",
      "{'loss': 3.2676, 'grad_norm': 7.8738837242126465, 'learning_rate': 3.371146015125073e-05, 'epoch': 0.49}\n",
      "{'loss': 3.194, 'grad_norm': 7.765528202056885, 'learning_rate': 3.356602675974404e-05, 'epoch': 0.49}\n",
      "{'loss': 3.1894, 'grad_norm': 8.675558090209961, 'learning_rate': 3.3420593368237346e-05, 'epoch': 0.5}\n",
      "{'loss': 3.24, 'grad_norm': 8.577594757080078, 'learning_rate': 3.3275159976730657e-05, 'epoch': 0.5}\n",
      " 33%|███████████                      | 11500/34380 [2:07:08<3:49:56,  1.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.18s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.63s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.262754, 'eval_rouge-2': 7.542114000000001, 'eval_rouge-l': 25.374668, 'eval_bleu-4': 0.03732514394679549, 'eval_runtime': 27.7748, 'eval_samples_per_second': 1.8, 'eval_steps_per_second': 0.144, 'epoch': 0.5}\n",
      " 33%|███████████                      | 11500/34380 [2:07:36<3:49:56,  1.66it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.96s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-11500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2312, 'grad_norm': 7.266880989074707, 'learning_rate': 3.312972658522397e-05, 'epoch': 0.51}\n",
      "{'loss': 3.2212, 'grad_norm': 9.147693634033203, 'learning_rate': 3.298429319371728e-05, 'epoch': 0.51}\n",
      "{'loss': 3.2266, 'grad_norm': 7.887938022613525, 'learning_rate': 3.283885980221059e-05, 'epoch': 0.51}\n",
      "{'loss': 3.257, 'grad_norm': 8.396478652954102, 'learning_rate': 3.26934264107039e-05, 'epoch': 0.52}\n",
      "{'loss': 3.2494, 'grad_norm': 8.250365257263184, 'learning_rate': 3.254799301919721e-05, 'epoch': 0.52}\n",
      " 35%|███████████▌                     | 12000/34380 [2:12:42<3:42:54,  1.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.420570000000005, 'eval_rouge-2': 7.264151999999999, 'eval_rouge-l': 23.891346, 'eval_bleu-4': 0.03507232927777068, 'eval_runtime': 42.453, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 0.094, 'epoch': 0.52}\n",
      " 35%|███████████▌                     | 12000/34380 [2:13:24<3:42:54,  1.67it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:30<00:00,  7.57s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-12000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2133, 'grad_norm': 7.856858730316162, 'learning_rate': 3.240255962769052e-05, 'epoch': 0.53}\n",
      "{'loss': 3.2013, 'grad_norm': 8.406203269958496, 'learning_rate': 3.2257126236183825e-05, 'epoch': 0.53}\n",
      "{'loss': 3.2163, 'grad_norm': 7.695734977722168, 'learning_rate': 3.2111692844677136e-05, 'epoch': 0.54}\n",
      "{'loss': 3.2612, 'grad_norm': 7.699513912200928, 'learning_rate': 3.196625945317045e-05, 'epoch': 0.54}\n",
      "{'loss': 3.2117, 'grad_norm': 7.580023288726807, 'learning_rate': 3.182082606166376e-05, 'epoch': 0.55}\n",
      " 36%|███████████▉                     | 12500/34380 [2:18:31<3:56:20,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.41s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.097064, 'eval_rouge-2': 7.6799159999999995, 'eval_rouge-l': 24.623709999999996, 'eval_bleu-4': 0.03603487446098161, 'eval_runtime': 27.5348, 'eval_samples_per_second': 1.816, 'eval_steps_per_second': 0.145, 'epoch': 0.55}\n",
      " 36%|███████████▉                     | 12500/34380 [2:18:58<3:56:20,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.11s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-12500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2298, 'grad_norm': 8.184666633605957, 'learning_rate': 3.167539267015707e-05, 'epoch': 0.55}\n",
      "{'loss': 3.2325, 'grad_norm': 8.208179473876953, 'learning_rate': 3.152995927865038e-05, 'epoch': 0.55}\n",
      "{'loss': 3.2353, 'grad_norm': 8.261805534362793, 'learning_rate': 3.138452588714369e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1807, 'grad_norm': 7.906728267669678, 'learning_rate': 3.1239092495637e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1337, 'grad_norm': 7.95728063583374, 'learning_rate': 3.1093659104130305e-05, 'epoch': 0.57}\n",
      " 38%|████████████▍                    | 13000/34380 [2:24:07<3:13:14,  1.84it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.054128, 'eval_rouge-2': 7.180846, 'eval_rouge-l': 24.290283999999996, 'eval_bleu-4': 0.0352237127949355, 'eval_runtime': 37.7049, 'eval_samples_per_second': 1.326, 'eval_steps_per_second': 0.106, 'epoch': 0.57}\n",
      " 38%|████████████▍                    | 13000/34380 [2:24:45<3:13:14,  1.84it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.80s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-13000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2235, 'grad_norm': 7.853506088256836, 'learning_rate': 3.0948225712623616e-05, 'epoch': 0.57}\n",
      "{'loss': 3.2094, 'grad_norm': 8.098388671875, 'learning_rate': 3.0802792321116933e-05, 'epoch': 0.58}\n",
      "{'loss': 3.1943, 'grad_norm': 7.965043544769287, 'learning_rate': 3.0657358929610244e-05, 'epoch': 0.58}\n",
      "{'loss': 3.2548, 'grad_norm': 8.04645824432373, 'learning_rate': 3.0511925538103548e-05, 'epoch': 0.58}\n",
      "{'loss': 3.2099, 'grad_norm': 8.05189037322998, 'learning_rate': 3.036649214659686e-05, 'epoch': 0.59}\n",
      " 39%|████████████▉                    | 13500/34380 [2:29:54<3:31:45,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.29s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.081428, 'eval_rouge-2': 7.730779999999999, 'eval_rouge-l': 24.257907999999993, 'eval_bleu-4': 0.037740156606998386, 'eval_runtime': 27.9534, 'eval_samples_per_second': 1.789, 'eval_steps_per_second': 0.143, 'epoch': 0.59}\n",
      " 39%|████████████▉                    | 13500/34380 [2:30:22<3:31:45,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.30s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-13500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2639, 'grad_norm': 8.6993408203125, 'learning_rate': 3.022105875509017e-05, 'epoch': 0.59}\n",
      "{'loss': 3.2361, 'grad_norm': 8.278862953186035, 'learning_rate': 3.007562536358348e-05, 'epoch': 0.6}\n",
      "{'loss': 3.1592, 'grad_norm': 8.710832595825195, 'learning_rate': 2.9930191972076788e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2345, 'grad_norm': 8.018457412719727, 'learning_rate': 2.97847585805701e-05, 'epoch': 0.61}\n",
      "{'loss': 3.2538, 'grad_norm': 8.038196563720703, 'learning_rate': 2.963932518906341e-05, 'epoch': 0.61}\n",
      " 41%|█████████████▍                   | 14000/34380 [2:35:28<3:20:57,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.14s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:17<00:05,  5.79s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.23013, 'eval_rouge-2': 7.233923999999999, 'eval_rouge-l': 23.327976000000003, 'eval_bleu-4': 0.03490210647954039, 'eval_runtime': 31.4788, 'eval_samples_per_second': 1.588, 'eval_steps_per_second': 0.127, 'epoch': 0.61}\n",
      " 41%|█████████████▍                   | 14000/34380 [2:36:00<3:20:57,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.14s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-14000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1887, 'grad_norm': 8.46654987335205, 'learning_rate': 2.949389179755672e-05, 'epoch': 0.62}\n",
      "{'loss': 3.2024, 'grad_norm': 8.303617477416992, 'learning_rate': 2.9348458406050028e-05, 'epoch': 0.62}\n",
      "{'loss': 3.2547, 'grad_norm': 7.85433292388916, 'learning_rate': 2.920302501454334e-05, 'epoch': 0.62}\n",
      "{'loss': 3.1949, 'grad_norm': 8.302388191223145, 'learning_rate': 2.905759162303665e-05, 'epoch': 0.63}\n",
      "{'loss': 3.2816, 'grad_norm': 7.99123477935791, 'learning_rate': 2.8912158231529964e-05, 'epoch': 0.63}\n",
      " 42%|█████████████▉                   | 14500/34380 [2:41:11<3:23:40,  1.63it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.02it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.54s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.837916, 'eval_rouge-2': 7.3066119999999986, 'eval_rouge-l': 26.323264000000005, 'eval_bleu-4': 0.037687838162514295, 'eval_runtime': 7.9634, 'eval_samples_per_second': 6.279, 'eval_steps_per_second': 0.502, 'epoch': 0.63}\n",
      " 42%|█████████████▉                   | 14500/34380 [2:41:19<3:23:40,  1.63it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.43s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-14500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.242, 'grad_norm': 8.205120086669922, 'learning_rate': 2.8766724840023268e-05, 'epoch': 0.64}\n",
      "{'loss': 3.218, 'grad_norm': 7.927493095397949, 'learning_rate': 2.862129144851658e-05, 'epoch': 0.64}\n",
      "{'loss': 3.2238, 'grad_norm': 8.386119842529297, 'learning_rate': 2.847585805700989e-05, 'epoch': 0.65}\n",
      "{'loss': 3.1925, 'grad_norm': 8.88548755645752, 'learning_rate': 2.8330424665503203e-05, 'epoch': 0.65}\n",
      "{'loss': 3.2156, 'grad_norm': 11.163135528564453, 'learning_rate': 2.8184991273996508e-05, 'epoch': 0.65}\n",
      " 44%|██████████████▍                  | 15000/34380 [2:46:28<3:17:04,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.02it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:05,  5.57s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.128374, 'eval_rouge-2': 7.526382, 'eval_rouge-l': 25.384561999999995, 'eval_bleu-4': 0.03511870934012379, 'eval_runtime': 17.9493, 'eval_samples_per_second': 2.786, 'eval_steps_per_second': 0.223, 'epoch': 0.65}\n",
      " 44%|██████████████▍                  | 15000/34380 [2:46:46<3:17:04,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.02s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-15000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2271, 'grad_norm': 8.120560646057129, 'learning_rate': 2.803955788248982e-05, 'epoch': 0.66}\n",
      "{'loss': 3.1892, 'grad_norm': 8.931718826293945, 'learning_rate': 2.7894124490983133e-05, 'epoch': 0.66}\n",
      "{'loss': 3.1981, 'grad_norm': 9.202682495117188, 'learning_rate': 2.7748691099476443e-05, 'epoch': 0.67}\n",
      "{'loss': 3.2039, 'grad_norm': 10.27122688293457, 'learning_rate': 2.7603257707969747e-05, 'epoch': 0.67}\n",
      "{'loss': 3.1887, 'grad_norm': 7.90279483795166, 'learning_rate': 2.745782431646306e-05, 'epoch': 0.68}\n",
      " 45%|██████████████▉                  | 15500/34380 [2:51:56<3:32:18,  1.48it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.51s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.57s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.0461, 'eval_rouge-2': 7.968854, 'eval_rouge-l': 25.42555999999999, 'eval_bleu-4': 0.039155330126130435, 'eval_runtime': 8.5933, 'eval_samples_per_second': 5.819, 'eval_steps_per_second': 0.465, 'epoch': 0.68}\n",
      " 45%|██████████████▉                  | 15500/34380 [2:52:05<3:32:18,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-15500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1737, 'grad_norm': 8.226831436157227, 'learning_rate': 2.7312390924956372e-05, 'epoch': 0.68}\n",
      "{'loss': 3.1809, 'grad_norm': 8.54875659942627, 'learning_rate': 2.7166957533449683e-05, 'epoch': 0.68}\n",
      "{'loss': 3.215, 'grad_norm': 8.798355102539062, 'learning_rate': 2.7021524141942987e-05, 'epoch': 0.69}\n",
      "{'loss': 3.2194, 'grad_norm': 10.0009765625, 'learning_rate': 2.68760907504363e-05, 'epoch': 0.69}\n",
      "{'loss': 3.2089, 'grad_norm': 8.396638870239258, 'learning_rate': 2.6730657358929612e-05, 'epoch': 0.7}\n",
      " 47%|███████████████▎                 | 16000/34380 [2:57:14<2:52:41,  1.77it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.10s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.27s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.815552, 'eval_rouge-2': 7.884902, 'eval_rouge-l': 26.104632000000002, 'eval_bleu-4': 0.03645343272331789, 'eval_runtime': 7.5427, 'eval_samples_per_second': 6.629, 'eval_steps_per_second': 0.53, 'epoch': 0.7}\n",
      " 47%|███████████████▎                 | 16000/34380 [2:57:21<2:52:41,  1.77it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-16000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2074, 'grad_norm': 7.939826965332031, 'learning_rate': 2.6585223967422923e-05, 'epoch': 0.7}\n",
      "{'loss': 3.2142, 'grad_norm': 8.295905113220215, 'learning_rate': 2.643979057591623e-05, 'epoch': 0.71}\n",
      "{'loss': 3.2277, 'grad_norm': 9.386737823486328, 'learning_rate': 2.629435718440954e-05, 'epoch': 0.71}\n",
      "{'loss': 3.1886, 'grad_norm': 8.591979026794434, 'learning_rate': 2.6148923792902852e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1893, 'grad_norm': 8.2844877243042, 'learning_rate': 2.6003490401396163e-05, 'epoch': 0.72}\n",
      " 48%|███████████████▊                 | 16500/34380 [3:02:29<2:59:27,  1.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.40s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.711858, 'eval_rouge-2': 7.5392280000000005, 'eval_rouge-l': 24.920029999999997, 'eval_bleu-4': 0.03518998868780937, 'eval_runtime': 17.974, 'eval_samples_per_second': 2.782, 'eval_steps_per_second': 0.223, 'epoch': 0.72}\n",
      " 48%|███████████████▊                 | 16500/34380 [3:02:47<2:59:27,  1.66it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.21s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-16500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.198, 'grad_norm': 8.526716232299805, 'learning_rate': 2.585805700988947e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1995, 'grad_norm': 9.305632591247559, 'learning_rate': 2.571262361838278e-05, 'epoch': 0.73}\n",
      "{'loss': 3.2682, 'grad_norm': 10.463774681091309, 'learning_rate': 2.5567190226876092e-05, 'epoch': 0.73}\n",
      "{'loss': 3.2075, 'grad_norm': 8.53322696685791, 'learning_rate': 2.5421756835369403e-05, 'epoch': 0.74}\n",
      "{'loss': 3.1896, 'grad_norm': 9.296619415283203, 'learning_rate': 2.527632344386271e-05, 'epoch': 0.74}\n",
      " 49%|████████████████▎                | 17000/34380 [3:07:56<3:08:06,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.62s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:06<00:02,  2.21s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.419658, 'eval_rouge-2': 8.099508, 'eval_rouge-l': 25.023402, 'eval_bleu-4': 0.03738613280924512, 'eval_runtime': 19.0214, 'eval_samples_per_second': 2.629, 'eval_steps_per_second': 0.21, 'epoch': 0.74}\n",
      " 49%|████████████████▎                | 17000/34380 [3:08:15<3:08:06,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.79s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-17000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1744, 'grad_norm': 8.19155502319336, 'learning_rate': 2.513089005235602e-05, 'epoch': 0.75}\n",
      "{'loss': 3.2057, 'grad_norm': 9.486016273498535, 'learning_rate': 2.498545666084933e-05, 'epoch': 0.75}\n",
      "{'loss': 3.2262, 'grad_norm': 9.049162864685059, 'learning_rate': 2.4840023269342642e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1759, 'grad_norm': 8.628340721130371, 'learning_rate': 2.4694589877835953e-05, 'epoch': 0.76}\n",
      "{'loss': 3.2052, 'grad_norm': 7.883338928222656, 'learning_rate': 2.454915648632926e-05, 'epoch': 0.76}\n",
      " 51%|████████████████▊                | 17500/34380 [3:13:24<2:50:13,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.35s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.621520000000004, 'eval_rouge-2': 8.42445, 'eval_rouge-l': 26.111117999999998, 'eval_bleu-4': 0.041541231941749614, 'eval_runtime': 17.5186, 'eval_samples_per_second': 2.854, 'eval_steps_per_second': 0.228, 'epoch': 0.76}\n",
      " 51%|████████████████▊                | 17500/34380 [3:13:42<2:50:13,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-17500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2201, 'grad_norm': 9.541754722595215, 'learning_rate': 2.440372309482257e-05, 'epoch': 0.77}\n",
      "{'loss': 3.206, 'grad_norm': 8.401947975158691, 'learning_rate': 2.4258289703315882e-05, 'epoch': 0.77}\n",
      "{'loss': 3.1784, 'grad_norm': 8.584676742553711, 'learning_rate': 2.4112856311809193e-05, 'epoch': 0.78}\n",
      "{'loss': 3.2289, 'grad_norm': 8.49845027923584, 'learning_rate': 2.39674229203025e-05, 'epoch': 0.78}\n",
      "{'loss': 3.2015, 'grad_norm': 9.286449432373047, 'learning_rate': 2.382198952879581e-05, 'epoch': 0.79}\n",
      " 52%|█████████████████▎               | 18000/34380 [3:18:50<3:00:05,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.24s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.794266, 'eval_rouge-2': 8.33604, 'eval_rouge-l': 25.600202, 'eval_bleu-4': 0.04154321374093086, 'eval_runtime': 19.4695, 'eval_samples_per_second': 2.568, 'eval_steps_per_second': 0.205, 'epoch': 0.79}\n",
      " 52%|█████████████████▎               | 18000/34380 [3:19:10<3:00:05,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  3.95s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-18000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1651, 'grad_norm': 8.721686363220215, 'learning_rate': 2.3676556137289122e-05, 'epoch': 0.79}\n",
      "{'loss': 3.2067, 'grad_norm': 8.951761245727539, 'learning_rate': 2.3531122745782433e-05, 'epoch': 0.79}\n",
      "{'loss': 3.1853, 'grad_norm': 9.244789123535156, 'learning_rate': 2.338568935427574e-05, 'epoch': 0.8}\n",
      "{'loss': 3.1738, 'grad_norm': 8.647390365600586, 'learning_rate': 2.3240255962769054e-05, 'epoch': 0.8}\n",
      "{'loss': 3.2233, 'grad_norm': 8.365044593811035, 'learning_rate': 2.3094822571262362e-05, 'epoch': 0.81}\n",
      " 54%|█████████████████▊               | 18500/34380 [3:24:17<2:34:06,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.27s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.50s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.409493999999995, 'eval_rouge-2': 6.909212, 'eval_rouge-l': 23.668452000000002, 'eval_bleu-4': 0.03367902708460212, 'eval_runtime': 17.5657, 'eval_samples_per_second': 2.846, 'eval_steps_per_second': 0.228, 'epoch': 0.81}\n",
      " 54%|█████████████████▊               | 18500/34380 [3:24:35<2:34:06,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.24s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-18500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1964, 'grad_norm': 8.897255897521973, 'learning_rate': 2.2949389179755673e-05, 'epoch': 0.81}\n",
      "{'loss': 3.1897, 'grad_norm': 8.19709587097168, 'learning_rate': 2.2803955788248983e-05, 'epoch': 0.82}\n",
      "{'loss': 3.1975, 'grad_norm': 9.125224113464355, 'learning_rate': 2.2658522396742294e-05, 'epoch': 0.82}\n",
      "{'loss': 3.196, 'grad_norm': 8.317977905273438, 'learning_rate': 2.25130890052356e-05, 'epoch': 0.82}\n",
      "{'loss': 3.2265, 'grad_norm': 10.138325691223145, 'learning_rate': 2.2367655613728912e-05, 'epoch': 0.83}\n",
      " 55%|██████████████████▏              | 19000/34380 [3:29:42<2:41:03,  1.59it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:15<00:04,  4.89s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.381767999999994, 'eval_rouge-2': 7.5018899999999995, 'eval_rouge-l': 25.59375, 'eval_bleu-4': 0.03668260419293807, 'eval_runtime': 26.5849, 'eval_samples_per_second': 1.881, 'eval_steps_per_second': 0.15, 'epoch': 0.83}\n",
      " 55%|██████████████████▏              | 19000/34380 [3:30:08<2:41:03,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:24<00:00,  6.47s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-19000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1648, 'grad_norm': 9.847461700439453, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.83}\n",
      "{'loss': 3.1847, 'grad_norm': 9.740543365478516, 'learning_rate': 2.2076788830715534e-05, 'epoch': 0.84}\n",
      "{'loss': 3.1835, 'grad_norm': 9.253098487854004, 'learning_rate': 2.193135543920884e-05, 'epoch': 0.84}\n",
      "{'loss': 3.1876, 'grad_norm': 9.295453071594238, 'learning_rate': 2.1785922047702152e-05, 'epoch': 0.85}\n",
      "{'loss': 3.2003, 'grad_norm': 8.859480857849121, 'learning_rate': 2.1640488656195463e-05, 'epoch': 0.85}\n",
      " 57%|██████████████████▋              | 19500/34380 [3:35:17<2:37:06,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.67s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.093372, 'eval_rouge-2': 8.571902, 'eval_rouge-l': 25.915026, 'eval_bleu-4': 0.03904396841335274, 'eval_runtime': 23.8068, 'eval_samples_per_second': 2.1, 'eval_steps_per_second': 0.168, 'epoch': 0.85}\n",
      " 57%|██████████████████▋              | 19500/34380 [3:35:41<2:37:06,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.03s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-19500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1887, 'grad_norm': 9.0303955078125, 'learning_rate': 2.1495055264688774e-05, 'epoch': 0.86}\n",
      "{'loss': 3.1716, 'grad_norm': 8.33660888671875, 'learning_rate': 2.134962187318208e-05, 'epoch': 0.86}\n",
      "{'loss': 3.1902, 'grad_norm': 8.988593101501465, 'learning_rate': 2.1204188481675396e-05, 'epoch': 0.86}\n",
      "{'loss': 3.2044, 'grad_norm': 9.47887134552002, 'learning_rate': 2.1058755090168703e-05, 'epoch': 0.87}\n",
      "{'loss': 3.1871, 'grad_norm': 8.98503589630127, 'learning_rate': 2.0913321698662014e-05, 'epoch': 0.87}\n",
      " 58%|███████████████████▏             | 20000/34380 [3:40:53<2:22:55,  1.68it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.16s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.194218, 'eval_rouge-2': 7.713316, 'eval_rouge-l': 26.662796, 'eval_bleu-4': 0.038903657416802344, 'eval_runtime': 6.8142, 'eval_samples_per_second': 7.338, 'eval_steps_per_second': 0.587, 'epoch': 0.87}\n",
      " 58%|███████████████████▏             | 20000/34380 [3:40:59<2:22:55,  1.68it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.23s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-20000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1734, 'grad_norm': 9.874920845031738, 'learning_rate': 2.076788830715532e-05, 'epoch': 0.88}\n",
      "{'loss': 3.1635, 'grad_norm': 8.620546340942383, 'learning_rate': 2.0622454915648635e-05, 'epoch': 0.88}\n",
      "{'loss': 3.198, 'grad_norm': 10.318142890930176, 'learning_rate': 2.0477021524141943e-05, 'epoch': 0.89}\n",
      "{'loss': 3.2028, 'grad_norm': 9.123063087463379, 'learning_rate': 2.0331588132635254e-05, 'epoch': 0.89}\n",
      "{'loss': 3.1743, 'grad_norm': 8.644681930541992, 'learning_rate': 2.0186154741128564e-05, 'epoch': 0.89}\n",
      " 60%|███████████████████▋             | 20500/34380 [3:46:11<2:13:35,  1.73it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.63s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.58s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.27088800000001, 'eval_rouge-2': 8.836329999999998, 'eval_rouge-l': 26.493470000000002, 'eval_bleu-4': 0.04382119813024517, 'eval_runtime': 13.6949, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 0.292, 'epoch': 0.89}\n",
      " 60%|███████████████████▋             | 20500/34380 [3:46:24<2:13:35,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-20500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1893, 'grad_norm': 9.053121566772461, 'learning_rate': 2.0040721349621875e-05, 'epoch': 0.9}\n",
      "{'loss': 3.2062, 'grad_norm': 8.853163719177246, 'learning_rate': 1.9895287958115183e-05, 'epoch': 0.9}\n",
      "{'loss': 3.1743, 'grad_norm': 8.706668853759766, 'learning_rate': 1.9749854566608493e-05, 'epoch': 0.91}\n",
      "{'loss': 3.1766, 'grad_norm': 9.299714088439941, 'learning_rate': 1.9604421175101804e-05, 'epoch': 0.91}\n",
      "{'loss': 3.2095, 'grad_norm': 10.940281867980957, 'learning_rate': 1.9458987783595115e-05, 'epoch': 0.92}\n",
      " 61%|████████████████████▏            | 21000/34380 [3:51:31<2:11:57,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.14s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.887342, 'eval_rouge-2': 7.802402, 'eval_rouge-l': 26.106630000000006, 'eval_bleu-4': 0.03743179942958618, 'eval_runtime': 15.3848, 'eval_samples_per_second': 3.25, 'eval_steps_per_second': 0.26, 'epoch': 0.92}\n",
      " 61%|████████████████████▏            | 21000/34380 [3:51:47<2:11:57,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  4.24s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-21000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2004, 'grad_norm': 10.442180633544922, 'learning_rate': 1.9313554392088422e-05, 'epoch': 0.92}\n",
      "{'loss': 3.2284, 'grad_norm': 9.282493591308594, 'learning_rate': 1.9168121000581733e-05, 'epoch': 0.92}\n",
      "{'loss': 3.184, 'grad_norm': 9.153033256530762, 'learning_rate': 1.9022687609075044e-05, 'epoch': 0.93}\n",
      "{'loss': 3.1808, 'grad_norm': 11.147210121154785, 'learning_rate': 1.8877254217568355e-05, 'epoch': 0.93}\n",
      "{'loss': 3.1555, 'grad_norm': 8.189934730529785, 'learning_rate': 1.8731820826061662e-05, 'epoch': 0.94}\n",
      " 63%|████████████████████▋            | 21500/34380 [3:56:57<2:07:09,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.97s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.75s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.059211999999995, 'eval_rouge-2': 8.415938, 'eval_rouge-l': 26.308584, 'eval_bleu-4': 0.04018421056184991, 'eval_runtime': 18.6403, 'eval_samples_per_second': 2.682, 'eval_steps_per_second': 0.215, 'epoch': 0.94}\n",
      " 63%|████████████████████▋            | 21500/34380 [3:57:15<2:07:09,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.42s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-21500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1955, 'grad_norm': 9.059236526489258, 'learning_rate': 1.8586387434554976e-05, 'epoch': 0.94}\n",
      "{'loss': 3.1716, 'grad_norm': 8.91242504119873, 'learning_rate': 1.8440954043048284e-05, 'epoch': 0.95}\n",
      "{'loss': 3.1752, 'grad_norm': 9.892066955566406, 'learning_rate': 1.8295520651541595e-05, 'epoch': 0.95}\n",
      "{'loss': 3.1445, 'grad_norm': 9.493873596191406, 'learning_rate': 1.8150087260034902e-05, 'epoch': 0.96}\n",
      "{'loss': 3.1989, 'grad_norm': 9.520758628845215, 'learning_rate': 1.8004653868528216e-05, 'epoch': 0.96}\n",
      " 64%|█████████████████████            | 22000/34380 [4:02:23<1:59:46,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.636808, 'eval_rouge-2': 6.911292, 'eval_rouge-l': 26.026794, 'eval_bleu-4': 0.03594996345736165, 'eval_runtime': 17.5613, 'eval_samples_per_second': 2.847, 'eval_steps_per_second': 0.228, 'epoch': 0.96}\n",
      " 64%|█████████████████████            | 22000/34380 [4:02:40<1:59:46,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.27s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-22000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1867, 'grad_norm': 8.339906692504883, 'learning_rate': 1.7859220477021524e-05, 'epoch': 0.96}\n",
      "{'loss': 3.1673, 'grad_norm': 9.474416732788086, 'learning_rate': 1.7713787085514834e-05, 'epoch': 0.97}\n",
      "{'loss': 3.1487, 'grad_norm': 8.717470169067383, 'learning_rate': 1.7568353694008145e-05, 'epoch': 0.97}\n",
      "{'loss': 3.1586, 'grad_norm': 8.677054405212402, 'learning_rate': 1.7422920302501456e-05, 'epoch': 0.98}\n",
      "{'loss': 3.143, 'grad_norm': 8.49153995513916, 'learning_rate': 1.7277486910994763e-05, 'epoch': 0.98}\n",
      " 65%|█████████████████████▌           | 22500/34380 [4:07:52<1:59:39,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.29s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.54s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.916982, 'eval_rouge-2': 7.762822, 'eval_rouge-l': 25.509776000000002, 'eval_bleu-4': 0.03929201280816807, 'eval_runtime': 7.8554, 'eval_samples_per_second': 6.365, 'eval_steps_per_second': 0.509, 'epoch': 0.98}\n",
      " 65%|█████████████████████▌           | 22500/34380 [4:08:00<1:59:39,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-22500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1803, 'grad_norm': 8.627764701843262, 'learning_rate': 1.7132053519488074e-05, 'epoch': 0.99}\n",
      "{'loss': 3.1719, 'grad_norm': 11.041980743408203, 'learning_rate': 1.6986620127981385e-05, 'epoch': 0.99}\n",
      "{'loss': 3.1999, 'grad_norm': 9.756752014160156, 'learning_rate': 1.6841186736474696e-05, 'epoch': 0.99}\n",
      "{'loss': 3.171, 'grad_norm': 9.105879783630371, 'learning_rate': 1.6695753344968003e-05, 'epoch': 1.0}\n",
      "{'loss': 3.1272, 'grad_norm': 8.607065200805664, 'learning_rate': 1.6550319953461314e-05, 'epoch': 1.0}\n",
      " 67%|██████████████████████           | 23000/34380 [4:13:09<2:06:20,  1.50it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.21s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.47s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.619285999999995, 'eval_rouge-2': 7.528326, 'eval_rouge-l': 25.071652, 'eval_bleu-4': 0.03648899520613289, 'eval_runtime': 17.6531, 'eval_samples_per_second': 2.832, 'eval_steps_per_second': 0.227, 'epoch': 1.0}\n",
      " 67%|██████████████████████           | 23000/34380 [4:13:26<2:06:20,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-23000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1778, 'grad_norm': 11.501176834106445, 'learning_rate': 1.6404886561954625e-05, 'epoch': 1.01}\n",
      "{'loss': 3.1014, 'grad_norm': 11.420047760009766, 'learning_rate': 1.6259453170447936e-05, 'epoch': 1.01}\n",
      "{'loss': 3.1705, 'grad_norm': 11.00725269317627, 'learning_rate': 1.6114019778941243e-05, 'epoch': 1.02}\n",
      "{'loss': 3.1121, 'grad_norm': 9.701531410217285, 'learning_rate': 1.5968586387434557e-05, 'epoch': 1.02}\n",
      "{'loss': 3.1338, 'grad_norm': 9.691447257995605, 'learning_rate': 1.5823152995927865e-05, 'epoch': 1.03}\n",
      " 68%|██████████████████████▌          | 23500/34380 [4:18:43<2:01:01,  1.50it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.48s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.58s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.729991999999996, 'eval_rouge-2': 7.1806399999999995, 'eval_rouge-l': 26.134384, 'eval_bleu-4': 0.03697717132610506, 'eval_runtime': 8.3252, 'eval_samples_per_second': 6.006, 'eval_steps_per_second': 0.48, 'epoch': 1.03}\n",
      " 68%|██████████████████████▌          | 23500/34380 [4:18:51<2:01:01,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.37s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-23500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1425, 'grad_norm': 9.039628028869629, 'learning_rate': 1.5677719604421175e-05, 'epoch': 1.03}\n",
      "{'loss': 3.1672, 'grad_norm': 10.049114227294922, 'learning_rate': 1.5532286212914486e-05, 'epoch': 1.03}\n",
      "{'loss': 3.1227, 'grad_norm': 10.039407730102539, 'learning_rate': 1.5386852821407797e-05, 'epoch': 1.04}\n",
      "{'loss': 3.1645, 'grad_norm': 9.925792694091797, 'learning_rate': 1.5241419429901105e-05, 'epoch': 1.04}\n",
      "{'loss': 3.1356, 'grad_norm': 9.81562328338623, 'learning_rate': 1.5095986038394417e-05, 'epoch': 1.05}\n",
      " 70%|███████████████████████          | 24000/34380 [4:24:02<1:45:13,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.31s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.284256, 'eval_rouge-2': 8.06432, 'eval_rouge-l': 25.864935999999997, 'eval_bleu-4': 0.03946983776280764, 'eval_runtime': 16.9268, 'eval_samples_per_second': 2.954, 'eval_steps_per_second': 0.236, 'epoch': 1.05}\n",
      " 70%|███████████████████████          | 24000/34380 [4:24:19<1:45:13,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.07s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-24000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1349, 'grad_norm': 11.064881324768066, 'learning_rate': 1.4950552646887724e-05, 'epoch': 1.05}\n",
      "{'loss': 3.1457, 'grad_norm': 10.23426342010498, 'learning_rate': 1.4805119255381037e-05, 'epoch': 1.06}\n",
      "{'loss': 3.1955, 'grad_norm': 9.419724464416504, 'learning_rate': 1.4659685863874344e-05, 'epoch': 1.06}\n",
      "{'loss': 3.1466, 'grad_norm': 8.40719223022461, 'learning_rate': 1.4514252472367657e-05, 'epoch': 1.06}\n",
      "{'loss': 3.1575, 'grad_norm': 9.344544410705566, 'learning_rate': 1.4368819080860966e-05, 'epoch': 1.07}\n",
      " 71%|███████████████████████▌         | 24500/34380 [4:29:29<1:48:58,  1.51it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.21s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:16<00:06,  6.24s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.575936, 'eval_rouge-2': 7.938990000000001, 'eval_rouge-l': 25.500303999999996, 'eval_bleu-4': 0.03858023322535888, 'eval_runtime': 27.7238, 'eval_samples_per_second': 1.804, 'eval_steps_per_second': 0.144, 'epoch': 1.07}\n",
      " 71%|███████████████████████▌         | 24500/34380 [4:29:57<1:48:58,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  7.31s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-24500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1404, 'grad_norm': 9.601197242736816, 'learning_rate': 1.4223385689354277e-05, 'epoch': 1.07}\n",
      "{'loss': 3.1317, 'grad_norm': 9.679092407226562, 'learning_rate': 1.4077952297847586e-05, 'epoch': 1.08}\n",
      "{'loss': 3.1505, 'grad_norm': 9.32908821105957, 'learning_rate': 1.3932518906340897e-05, 'epoch': 1.08}\n",
      "{'loss': 3.1173, 'grad_norm': 11.447206497192383, 'learning_rate': 1.3787085514834206e-05, 'epoch': 1.09}\n",
      "{'loss': 3.139, 'grad_norm': 9.81920051574707, 'learning_rate': 1.3641652123327517e-05, 'epoch': 1.09}\n",
      " 73%|███████████████████████▉         | 25000/34380 [4:35:06<1:30:25,  1.73it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.02s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:05,  5.55s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.391446, 'eval_rouge-2': 7.766861999999999, 'eval_rouge-l': 26.059072, 'eval_bleu-4': 0.03765372626792409, 'eval_runtime': 16.9827, 'eval_samples_per_second': 2.944, 'eval_steps_per_second': 0.236, 'epoch': 1.09}\n",
      " 73%|███████████████████████▉         | 25000/34380 [4:35:23<1:30:25,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.85s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-25000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1812, 'grad_norm': 10.005316734313965, 'learning_rate': 1.3496218731820826e-05, 'epoch': 1.1}\n",
      "{'loss': 3.1712, 'grad_norm': 9.624384880065918, 'learning_rate': 1.3350785340314136e-05, 'epoch': 1.1}\n",
      "{'loss': 3.1151, 'grad_norm': 9.797898292541504, 'learning_rate': 1.3205351948807446e-05, 'epoch': 1.1}\n",
      "{'loss': 3.1309, 'grad_norm': 9.215513229370117, 'learning_rate': 1.3059918557300756e-05, 'epoch': 1.11}\n",
      "{'loss': 3.1927, 'grad_norm': 9.444422721862793, 'learning_rate': 1.2914485165794065e-05, 'epoch': 1.11}\n",
      " 74%|████████████████████████▍        | 25500/34380 [4:40:33<1:27:37,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:16<00:05,  5.19s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.945434000000006, 'eval_rouge-2': 7.711155999999999, 'eval_rouge-l': 25.173368, 'eval_bleu-4': 0.03544879816034811, 'eval_runtime': 29.5866, 'eval_samples_per_second': 1.69, 'eval_steps_per_second': 0.135, 'epoch': 1.11}\n",
      " 74%|████████████████████████▍        | 25500/34380 [4:41:03<1:27:37,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  3.66s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-25500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1418, 'grad_norm': 10.090699195861816, 'learning_rate': 1.2769051774287378e-05, 'epoch': 1.12}\n",
      "{'loss': 3.1589, 'grad_norm': 9.862929344177246, 'learning_rate': 1.2623618382780685e-05, 'epoch': 1.12}\n",
      "{'loss': 3.1514, 'grad_norm': 10.778470993041992, 'learning_rate': 1.2478184991273998e-05, 'epoch': 1.13}\n",
      "{'loss': 3.1681, 'grad_norm': 9.437505722045898, 'learning_rate': 1.2332751599767307e-05, 'epoch': 1.13}\n",
      "{'loss': 3.1295, 'grad_norm': 8.846708297729492, 'learning_rate': 1.2187318208260618e-05, 'epoch': 1.13}\n",
      " 76%|████████████████████████▉        | 26000/34380 [4:46:20<1:29:50,  1.55it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.44s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.53s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.782364, 'eval_rouge-2': 7.572869999999999, 'eval_rouge-l': 26.450671999999994, 'eval_bleu-4': 0.03802392310878107, 'eval_runtime': 7.5455, 'eval_samples_per_second': 6.626, 'eval_steps_per_second': 0.53, 'epoch': 1.13}\n",
      " 76%|████████████████████████▉        | 26000/34380 [4:46:28<1:29:50,  1.55it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-26000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1586, 'grad_norm': 9.815359115600586, 'learning_rate': 1.2041884816753927e-05, 'epoch': 1.14}\n",
      "{'loss': 3.166, 'grad_norm': 10.129549026489258, 'learning_rate': 1.1896451425247238e-05, 'epoch': 1.14}\n",
      "{'loss': 3.1603, 'grad_norm': 9.81931209564209, 'learning_rate': 1.1751018033740547e-05, 'epoch': 1.15}\n",
      "{'loss': 3.1592, 'grad_norm': 12.366113662719727, 'learning_rate': 1.1605584642233858e-05, 'epoch': 1.15}\n",
      "{'loss': 3.1461, 'grad_norm': 9.92140007019043, 'learning_rate': 1.1460151250727168e-05, 'epoch': 1.16}\n",
      " 77%|█████████████████████████▍       | 26500/34380 [4:51:34<1:24:09,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.36s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.51s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.334562, 'eval_rouge-2': 7.865430000000001, 'eval_rouge-l': 26.567885999999998, 'eval_bleu-4': 0.03731869136857349, 'eval_runtime': 15.3894, 'eval_samples_per_second': 3.249, 'eval_steps_per_second': 0.26, 'epoch': 1.16}\n",
      " 77%|█████████████████████████▍       | 26500/34380 [4:51:49<1:24:09,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  4.35s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-26500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1776, 'grad_norm': 8.963644981384277, 'learning_rate': 1.1314717859220478e-05, 'epoch': 1.16}\n",
      "{'loss': 3.1707, 'grad_norm': 10.109374046325684, 'learning_rate': 1.1169284467713788e-05, 'epoch': 1.16}\n",
      "{'loss': 3.1914, 'grad_norm': 9.303648948669434, 'learning_rate': 1.1023851076207097e-05, 'epoch': 1.17}\n",
      "{'loss': 3.1321, 'grad_norm': 9.981646537780762, 'learning_rate': 1.0878417684700408e-05, 'epoch': 1.17}\n",
      "{'loss': 3.1555, 'grad_norm': 9.903374671936035, 'learning_rate': 1.0732984293193717e-05, 'epoch': 1.18}\n",
      " 79%|█████████████████████████▉       | 27000/34380 [4:56:57<1:11:54,  1.71it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.55s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.63s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.915138, 'eval_rouge-2': 7.571738000000002, 'eval_rouge-l': 25.637736, 'eval_bleu-4': 0.03801088496237645, 'eval_runtime': 17.0874, 'eval_samples_per_second': 2.926, 'eval_steps_per_second': 0.234, 'epoch': 1.18}\n",
      " 79%|█████████████████████████▉       | 27000/34380 [4:57:14<1:11:54,  1.71it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.50s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-27000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1597, 'grad_norm': 10.871451377868652, 'learning_rate': 1.0587550901687028e-05, 'epoch': 1.18}\n",
      "{'loss': 3.1359, 'grad_norm': 11.363072395324707, 'learning_rate': 1.0442117510180339e-05, 'epoch': 1.19}\n",
      "{'loss': 3.1516, 'grad_norm': 10.225354194641113, 'learning_rate': 1.0296684118673648e-05, 'epoch': 1.19}\n",
      "{'loss': 3.1695, 'grad_norm': 9.54193115234375, 'learning_rate': 1.0151250727166959e-05, 'epoch': 1.2}\n",
      "{'loss': 3.1899, 'grad_norm': 9.430377006530762, 'learning_rate': 1.0005817335660268e-05, 'epoch': 1.2}\n",
      " 80%|██████████████████████████▍      | 27500/34380 [5:02:24<1:09:37,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.20s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.451434000000006, 'eval_rouge-2': 7.598388000000001, 'eval_rouge-l': 25.123442, 'eval_bleu-4': 0.03581288992087937, 'eval_runtime': 23.2787, 'eval_samples_per_second': 2.148, 'eval_steps_per_second': 0.172, 'epoch': 1.2}\n",
      " 80%|██████████████████████████▍      | 27500/34380 [5:02:47<1:09:37,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.03s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-27500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1246, 'grad_norm': 9.935742378234863, 'learning_rate': 9.860383944153579e-06, 'epoch': 1.2}\n",
      "{'loss': 3.1775, 'grad_norm': 10.290094375610352, 'learning_rate': 9.714950552646888e-06, 'epoch': 1.21}\n",
      "{'loss': 3.1628, 'grad_norm': 9.710939407348633, 'learning_rate': 9.569517161140199e-06, 'epoch': 1.21}\n",
      "{'loss': 3.1757, 'grad_norm': 9.876148223876953, 'learning_rate': 9.424083769633508e-06, 'epoch': 1.22}\n",
      "{'loss': 3.1419, 'grad_norm': 10.443401336669922, 'learning_rate': 9.278650378126819e-06, 'epoch': 1.22}\n",
      " 81%|██████████████████████████▉      | 28000/34380 [5:07:57<1:04:41,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.38s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.351912, 'eval_rouge-2': 7.376956000000002, 'eval_rouge-l': 25.567488000000004, 'eval_bleu-4': 0.03645273926535476, 'eval_runtime': 11.743, 'eval_samples_per_second': 4.258, 'eval_steps_per_second': 0.341, 'epoch': 1.22}\n",
      " 81%|██████████████████████████▉      | 28000/34380 [5:08:09<1:04:41,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.21s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-28000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1326, 'grad_norm': 9.526766777038574, 'learning_rate': 9.13321698662013e-06, 'epoch': 1.23}\n",
      "{'loss': 3.1763, 'grad_norm': 8.92110538482666, 'learning_rate': 8.987783595113439e-06, 'epoch': 1.23}\n",
      "{'loss': 3.1448, 'grad_norm': 9.769050598144531, 'learning_rate': 8.84235020360675e-06, 'epoch': 1.23}\n",
      "{'loss': 3.2051, 'grad_norm': 10.095192909240723, 'learning_rate': 8.696916812100058e-06, 'epoch': 1.24}\n",
      "{'loss': 3.1322, 'grad_norm': 10.927847862243652, 'learning_rate': 8.55148342059337e-06, 'epoch': 1.24}\n",
      " 83%|█████████████████████████████      | 28500/34380 [5:13:18<59:53,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.20s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.766402, 'eval_rouge-2': 7.549531999999999, 'eval_rouge-l': 25.273794000000002, 'eval_bleu-4': 0.03544751538481834, 'eval_runtime': 16.6512, 'eval_samples_per_second': 3.003, 'eval_steps_per_second': 0.24, 'epoch': 1.24}\n",
      " 83%|█████████████████████████████      | 28500/34380 [5:13:35<59:53,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.04s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-28500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.113, 'grad_norm': 10.306183815002441, 'learning_rate': 8.406050029086678e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1468, 'grad_norm': 9.629598617553711, 'learning_rate': 8.260616637579989e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1186, 'grad_norm': 9.371172904968262, 'learning_rate': 8.115183246073298e-06, 'epoch': 1.26}\n",
      "{'loss': 3.1305, 'grad_norm': 9.336700439453125, 'learning_rate': 7.969749854566609e-06, 'epoch': 1.26}\n",
      "{'loss': 3.1542, 'grad_norm': 12.013757705688477, 'learning_rate': 7.82431646305992e-06, 'epoch': 1.27}\n",
      " 84%|█████████████████████████████▌     | 29000/34380 [5:18:46<55:19,  1.62it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.04s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.20s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.432096, 'eval_rouge-2': 7.484956000000002, 'eval_rouge-l': 25.452722000000005, 'eval_bleu-4': 0.038217382712147564, 'eval_runtime': 17.4461, 'eval_samples_per_second': 2.866, 'eval_steps_per_second': 0.229, 'epoch': 1.27}\n",
      " 84%|█████████████████████████████▌     | 29000/34380 [5:19:04<55:19,  1.62it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-29000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1559, 'grad_norm': 10.81466007232666, 'learning_rate': 7.678883071553229e-06, 'epoch': 1.27}\n",
      "{'loss': 3.1663, 'grad_norm': 9.08803653717041, 'learning_rate': 7.533449680046539e-06, 'epoch': 1.27}\n",
      "{'loss': 3.1275, 'grad_norm': 11.0302095413208, 'learning_rate': 7.38801628853985e-06, 'epoch': 1.28}\n",
      "{'loss': 3.1853, 'grad_norm': 10.48183536529541, 'learning_rate': 7.24258289703316e-06, 'epoch': 1.28}\n",
      "{'loss': 3.1132, 'grad_norm': 9.83420181274414, 'learning_rate': 7.09714950552647e-06, 'epoch': 1.29}\n",
      " 86%|██████████████████████████████     | 29500/34380 [5:24:12<46:59,  1.73it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.03s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.22s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.202884, 'eval_rouge-2': 7.653122000000001, 'eval_rouge-l': 25.898445999999993, 'eval_bleu-4': 0.03783494704005493, 'eval_runtime': 6.377, 'eval_samples_per_second': 7.841, 'eval_steps_per_second': 0.627, 'epoch': 1.29}\n",
      " 86%|██████████████████████████████     | 29500/34380 [5:24:18<46:59,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-29500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1147, 'grad_norm': 10.067401885986328, 'learning_rate': 6.9517161140197796e-06, 'epoch': 1.29}\n",
      "{'loss': 3.1296, 'grad_norm': 10.998579025268555, 'learning_rate': 6.8062827225130895e-06, 'epoch': 1.3}\n",
      "{'loss': 3.1292, 'grad_norm': 9.621427536010742, 'learning_rate': 6.6608493310063995e-06, 'epoch': 1.3}\n",
      "{'loss': 3.1402, 'grad_norm': 9.697392463684082, 'learning_rate': 6.5154159394997094e-06, 'epoch': 1.3}\n",
      "{'loss': 3.114, 'grad_norm': 10.347485542297363, 'learning_rate': 6.369982547993019e-06, 'epoch': 1.31}\n",
      " 87%|██████████████████████████████▌    | 30000/34380 [5:29:26<47:56,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.29s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.91s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.724712, 'eval_rouge-2': 7.385546000000001, 'eval_rouge-l': 25.645838000000005, 'eval_bleu-4': 0.035870632684802915, 'eval_runtime': 18.495, 'eval_samples_per_second': 2.703, 'eval_steps_per_second': 0.216, 'epoch': 1.31}\n",
      " 87%|██████████████████████████████▌    | 30000/34380 [5:29:45<47:56,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.48s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-30000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1425, 'grad_norm': 9.69785213470459, 'learning_rate': 6.22454915648633e-06, 'epoch': 1.31}\n",
      "{'loss': 3.1189, 'grad_norm': 10.906089782714844, 'learning_rate': 6.07911576497964e-06, 'epoch': 1.32}\n",
      "{'loss': 3.1658, 'grad_norm': 10.275089263916016, 'learning_rate': 5.93368237347295e-06, 'epoch': 1.32}\n",
      "{'loss': 3.166, 'grad_norm': 10.361126899719238, 'learning_rate': 5.78824898196626e-06, 'epoch': 1.33}\n",
      "{'loss': 3.1182, 'grad_norm': 11.111418724060059, 'learning_rate': 5.64281559045957e-06, 'epoch': 1.33}\n",
      " 89%|███████████████████████████████    | 30500/34380 [5:34:52<41:53,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.59s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.86s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.655012000000006, 'eval_rouge-2': 7.587047999999999, 'eval_rouge-l': 25.679318, 'eval_bleu-4': 0.03770266751337778, 'eval_runtime': 8.7135, 'eval_samples_per_second': 5.738, 'eval_steps_per_second': 0.459, 'epoch': 1.33}\n",
      " 89%|███████████████████████████████    | 30500/34380 [5:35:01<41:53,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.63s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-30500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1554, 'grad_norm': 9.820489883422852, 'learning_rate': 5.49738219895288e-06, 'epoch': 1.34}\n",
      "{'loss': 3.1113, 'grad_norm': 10.787487030029297, 'learning_rate': 5.35194880744619e-06, 'epoch': 1.34}\n",
      "{'loss': 3.1683, 'grad_norm': 10.518128395080566, 'learning_rate': 5.2065154159395e-06, 'epoch': 1.34}\n",
      "{'loss': 3.119, 'grad_norm': 10.444401741027832, 'learning_rate': 5.061082024432811e-06, 'epoch': 1.35}\n",
      "{'loss': 3.1605, 'grad_norm': 9.900869369506836, 'learning_rate': 4.915648632926121e-06, 'epoch': 1.35}\n",
      " 90%|███████████████████████████████▌   | 31000/34380 [5:40:08<37:15,  1.51it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.10s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.59s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.2748, 'eval_rouge-2': 7.330506000000001, 'eval_rouge-l': 25.318206, 'eval_bleu-4': 0.03627553150244002, 'eval_runtime': 17.6513, 'eval_samples_per_second': 2.833, 'eval_steps_per_second': 0.227, 'epoch': 1.35}\n",
      " 90%|███████████████████████████████▌   | 31000/34380 [5:40:25<37:15,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.92s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-31000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1646, 'grad_norm': 10.429773330688477, 'learning_rate': 4.770215241419431e-06, 'epoch': 1.36}\n",
      "{'loss': 3.1654, 'grad_norm': 9.863712310791016, 'learning_rate': 4.6247818499127406e-06, 'epoch': 1.36}\n",
      "{'loss': 3.1172, 'grad_norm': 10.74647331237793, 'learning_rate': 4.4793484584060505e-06, 'epoch': 1.37}\n",
      "{'loss': 3.1735, 'grad_norm': 10.074335098266602, 'learning_rate': 4.3339150668993605e-06, 'epoch': 1.37}\n",
      "{'loss': 3.1507, 'grad_norm': 10.487956047058105, 'learning_rate': 4.18848167539267e-06, 'epoch': 1.37}\n",
      " 92%|████████████████████████████████   | 31500/34380 [5:45:35<29:00,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.49s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.81s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.780772, 'eval_rouge-2': 6.4551240000000005, 'eval_rouge-l': 24.572743999999997, 'eval_bleu-4': 0.032950549500842675, 'eval_runtime': 28.6395, 'eval_samples_per_second': 1.746, 'eval_steps_per_second': 0.14, 'epoch': 1.37}\n",
      " 92%|████████████████████████████████   | 31500/34380 [5:46:03<29:00,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  4.17s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-31500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.115, 'grad_norm': 10.906929016113281, 'learning_rate': 4.04304828388598e-06, 'epoch': 1.38}\n",
      "{'loss': 3.1353, 'grad_norm': 10.445676803588867, 'learning_rate': 3.89761489237929e-06, 'epoch': 1.38}\n",
      "{'loss': 3.0944, 'grad_norm': 11.154529571533203, 'learning_rate': 3.7521815008726007e-06, 'epoch': 1.39}\n",
      "{'loss': 3.1412, 'grad_norm': 9.733614921569824, 'learning_rate': 3.6067481093659107e-06, 'epoch': 1.39}\n",
      "{'loss': 3.119, 'grad_norm': 10.776786804199219, 'learning_rate': 3.461314717859221e-06, 'epoch': 1.4}\n",
      " 93%|████████████████████████████████▌  | 32000/34380 [5:51:09<24:33,  1.61it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:09<00:09,  4.57s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:12<00:03,  3.88s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.875118, 'eval_rouge-2': 7.527262, 'eval_rouge-l': 25.7432, 'eval_bleu-4': 0.03483902998476084, 'eval_runtime': 15.0478, 'eval_samples_per_second': 3.323, 'eval_steps_per_second': 0.266, 'epoch': 1.4}\n",
      " 93%|████████████████████████████████▌  | 32000/34380 [5:51:24<24:33,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  2.91s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-32000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.114, 'grad_norm': 10.023058891296387, 'learning_rate': 3.315881326352531e-06, 'epoch': 1.4}\n",
      "{'loss': 3.1663, 'grad_norm': 10.444805145263672, 'learning_rate': 3.170447934845841e-06, 'epoch': 1.4}\n",
      "{'loss': 3.1275, 'grad_norm': 9.67929458618164, 'learning_rate': 3.025014543339151e-06, 'epoch': 1.41}\n",
      "{'loss': 3.1457, 'grad_norm': 10.392138481140137, 'learning_rate': 2.879581151832461e-06, 'epoch': 1.41}\n",
      "{'loss': 3.1742, 'grad_norm': 9.952996253967285, 'learning_rate': 2.734147760325771e-06, 'epoch': 1.42}\n",
      " 95%|█████████████████████████████████  | 32500/34380 [5:56:40<20:05,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.23s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.269853999999995, 'eval_rouge-2': 7.549944, 'eval_rouge-l': 25.824209999999997, 'eval_bleu-4': 0.037562645703108986, 'eval_runtime': 7.0354, 'eval_samples_per_second': 7.107, 'eval_steps_per_second': 0.569, 'epoch': 1.42}\n",
      " 95%|█████████████████████████████████  | 32500/34380 [5:56:47<20:05,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-32500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1054, 'grad_norm': 10.938279151916504, 'learning_rate': 2.5887143688190808e-06, 'epoch': 1.42}\n",
      "{'loss': 3.1439, 'grad_norm': 10.936408996582031, 'learning_rate': 2.443280977312391e-06, 'epoch': 1.43}\n",
      "{'loss': 3.1361, 'grad_norm': 10.4638090133667, 'learning_rate': 2.297847585805701e-06, 'epoch': 1.43}\n",
      "{'loss': 3.1694, 'grad_norm': 10.734414100646973, 'learning_rate': 2.152414194299011e-06, 'epoch': 1.44}\n",
      "{'loss': 3.094, 'grad_norm': 11.088478088378906, 'learning_rate': 2.006980802792321e-06, 'epoch': 1.44}\n",
      " 96%|█████████████████████████████████▌ | 33000/34380 [6:01:55<13:48,  1.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.83s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.80s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.208358, 'eval_rouge-2': 7.584094, 'eval_rouge-l': 25.885885999999996, 'eval_bleu-4': 0.03735637803842717, 'eval_runtime': 18.7299, 'eval_samples_per_second': 2.67, 'eval_steps_per_second': 0.214, 'epoch': 1.44}\n",
      " 96%|█████████████████████████████████▌ | 33000/34380 [6:02:13<13:48,  1.67it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.48s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-33000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.145, 'grad_norm': 10.291117668151855, 'learning_rate': 1.8615474112856312e-06, 'epoch': 1.44}\n",
      "{'loss': 3.1367, 'grad_norm': 10.353673934936523, 'learning_rate': 1.7161140197789413e-06, 'epoch': 1.45}\n",
      "{'loss': 3.1527, 'grad_norm': 10.58617115020752, 'learning_rate': 1.5706806282722513e-06, 'epoch': 1.45}\n",
      "{'loss': 3.1548, 'grad_norm': 10.93664836883545, 'learning_rate': 1.4252472367655615e-06, 'epoch': 1.46}\n",
      "{'loss': 3.1752, 'grad_norm': 10.429716110229492, 'learning_rate': 1.2798138452588714e-06, 'epoch': 1.46}\n",
      " 97%|██████████████████████████████████ | 33500/34380 [6:07:19<09:23,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.02it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.16s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.024272, 'eval_rouge-2': 7.909097999999999, 'eval_rouge-l': 26.085804, 'eval_bleu-4': 0.03855216206779577, 'eval_runtime': 6.0083, 'eval_samples_per_second': 8.322, 'eval_steps_per_second': 0.666, 'epoch': 1.46}\n",
      " 97%|██████████████████████████████████ | 33500/34380 [6:07:25<09:23,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.10s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-33500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1488, 'grad_norm': 10.082915306091309, 'learning_rate': 1.1343804537521814e-06, 'epoch': 1.47}\n",
      "{'loss': 3.144, 'grad_norm': 11.362931251525879, 'learning_rate': 9.889470622454915e-07, 'epoch': 1.47}\n",
      "{'loss': 3.1688, 'grad_norm': 10.324328422546387, 'learning_rate': 8.435136707388016e-07, 'epoch': 1.47}\n",
      "{'loss': 3.1441, 'grad_norm': 11.271061897277832, 'learning_rate': 6.980802792321118e-07, 'epoch': 1.48}\n",
      "{'loss': 3.129, 'grad_norm': 10.298580169677734, 'learning_rate': 5.526468877254218e-07, 'epoch': 1.48}\n",
      " 99%|██████████████████████████████████▌| 34000/34380 [6:12:28<04:02,  1.57it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.38s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.52s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.752542000000005, 'eval_rouge-2': 7.5296780000000005, 'eval_rouge-l': 25.882006, 'eval_bleu-4': 0.037440682284833576, 'eval_runtime': 18.2784, 'eval_samples_per_second': 2.735, 'eval_steps_per_second': 0.219, 'epoch': 1.48}\n",
      " 99%|██████████████████████████████████▌| 34000/34380 [6:12:46<04:02,  1.57it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.48s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-34000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.0857, 'grad_norm': 10.675752639770508, 'learning_rate': 4.0721349621873184e-07, 'epoch': 1.49}\n",
      "{'loss': 3.1347, 'grad_norm': 9.38550853729248, 'learning_rate': 2.617801047120419e-07, 'epoch': 1.49}\n",
      "{'loss': 3.118, 'grad_norm': 10.250651359558105, 'learning_rate': 1.1634671320535195e-07, 'epoch': 1.5}\n",
      "100%|███████████████████████████████████| 34380/34380 [6:16:38<00:00,  1.72it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 22598.5027, 'train_samples_per_second': 7.607, 'train_steps_per_second': 1.521, 'train_loss': 3.226332022160413, 'epoch': 1.5}\n",
      "100%|███████████████████████████████████| 34380/34380 [6:16:38<00:00,  1.52it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [03:27<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python finetune_hf.py  data/AdvertiseGen_fix  THUDM/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5060015c24e97ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5060015c24e97ae",
    "outputId": "d3f03d0d-46bf-4c74-9b00-dc0160da0e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:01<00:00,  5.48it/s]\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "这款连衣裙采用不规则的裙摆设计，轻松打造出时尚的层次感，带来别致的视觉体验。套头拉链的门襟，方便穿脱，穿脱更加方便。百褶拼接的领口，性感迷人，凸显女性魅力。百褶的袖口，修饰手臂曲线，修饰手臂纤细。百褶的裙摆，百褶的层数丰富，轻盈飘逸，行走之间，飘逸灵动。网纱的裙摆，轻盈飘逸，带出浪漫气息。腰间的木耳边装饰，修身显瘦。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-34000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T10:22:22.412779Z",
     "start_time": "2024-07-22T10:22:15.657625Z"
    }
   },
   "cell_type": "code",
   "source": "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-500/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\"",
   "id": "fd701125e60cc1e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\n",
      "  warnings.warn(\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:01<00:00,  5.67it/s]\r\n",
      "Setting eos_token is not supported, use the default one.\r\n",
      "Setting pad_token is not supported, use the default one.\r\n",
      "Setting unk_token is not supported, use the default one.\r\n",
      "这款连衣裙是款性感的包臀连衣裙，精选优质纯棉面料，触感柔软亲肤，穿着舒适不刺激。而网纱的拼接，让整体更具时尚感，更显青春活力。而裙摆的木耳边装饰，让整体更显气质。而拉链的装饰，更是方便实用。而袖口的不规则设计，更显个性。\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "markdown",
   "id": "18cd83087f096094",
   "metadata": {
    "collapsed": false,
    "id": "18cd83087f096094",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 4. 总结\n",
    "到此位置，我们就完成了使用单张 GPU Lora 来微调 ChatGLM3-6B 模型，使其能生产出更好的广告。\n",
    "在本章节中，你将会学会：\n",
    "+ 如何使用模型进行 Lora 微调\n",
    "+ 微调数据集的准备和对齐\n",
    "+ 使用微调的模型进行推理"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
