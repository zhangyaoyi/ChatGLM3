{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89b89f64d8f8053d",
   "metadata": {
    "collapsed": false,
    "id": "89b89f64d8f8053d",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# 单卡GPU 进行 ChatGLM3-6B模型 LORA 高效微调\n",
    "本 Cookbook 将带领开发者使用 `AdvertiseGen` 对 ChatGLM3-6B 数据集进行 lora微调，使其具备专业的广告生成能力。\n",
    "\n",
    "## 硬件需求\n",
    "显存：24GB及以上（推荐使用30系或A10等sm80架构以上的NVIDIA显卡进行尝试）\n",
    "内存：16GB\n",
    "RAM: 2.9 /16 GB\n",
    "GPU RAM: 15.5/16.0 GB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bd9a514ed09ea6",
   "metadata": {
    "collapsed": false,
    "id": "a7bd9a514ed09ea6",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 0. 环境检查\n",
    "首先，先检查代码的运行地址，确保运行地址处于 `finetune_demo` 中。\n",
    "并且，确保已经安装了 `requirements.txt`中的依赖。\n",
    "\n",
    "> 本 demo 中，不需要使用 deepspeed, mpi4py 两个依赖，如果您安装这两个依赖遇到问题，可以不安装这两个依赖。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7703109d1443346",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/Workspace/ChatGLM3/finetune_demo\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f50e92810011977",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 1. 准备数据集\n",
    "我们使用 AdvertiseGen 数据集来进行微调。从 [Google Drive](https://drive.google.com/file/d/13_vf0xRTQsyneRKdD1bZIr93vBGOczrk/view?usp=sharing) 或者 [Tsinghua Cloud](https://cloud.tsinghua.edu.cn/f/b3f119a008264b1cabd1/?dl=1) 下载处理好的 AdvertiseGen 数据集，将解压后的 AdvertiseGen 目录放到本目录的 `/data/` 下, 例如。\n",
    "> /media/zr/Data/Code/ChatGLM3/finetune_demo/data/AdvertiseGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "cellView": "form",
    "id": "initial_id"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import Union\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "def _resolve_path(path: Union[str, Path]) -> Path:\n",
    "    return Path(path).expanduser().resolve()\n",
    "\n",
    "\n",
    "def _mkdir(dir_name: Union[str, Path]):\n",
    "    dir_name = _resolve_path(dir_name)\n",
    "    if not dir_name.is_dir():\n",
    "        dir_name.mkdir(parents=True, exist_ok=False)\n",
    "\n",
    "\n",
    "def convert_adgen(data_dir: Union[str, Path], save_dir: Union[str, Path]):\n",
    "    def _convert(in_file: Path, out_file: Path):\n",
    "        _mkdir(out_file.parent)\n",
    "        with open(in_file, encoding='utf-8') as fin:\n",
    "            with open(out_file, 'wt', encoding='utf-8') as fout:\n",
    "                for line in fin:\n",
    "                    dct = json.loads(line)\n",
    "                    sample = {'conversations': [{'role': 'user', 'content': dct['content']},\n",
    "                                                {'role': 'assistant', 'content': dct['summary']}]}\n",
    "                    fout.write(json.dumps(sample, ensure_ascii=False) + '\\n')\n",
    "\n",
    "    data_dir = _resolve_path(data_dir)\n",
    "    save_dir = _resolve_path(save_dir)\n",
    "\n",
    "    train_file = data_dir / 'train.json'\n",
    "    if train_file.is_file():\n",
    "        out_file = save_dir / train_file.relative_to(data_dir)\n",
    "        _convert(train_file, out_file)\n",
    "\n",
    "    dev_file = data_dir / 'dev.json'\n",
    "    if dev_file.is_file():\n",
    "        out_file = save_dir / dev_file.relative_to(data_dir)\n",
    "        _convert(dev_file, out_file)\n",
    "\n",
    "\n",
    "convert_adgen('data/AdvertiseGen', 'data/AdvertiseGen_fix')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1b7a99923349056",
   "metadata": {
    "collapsed": false,
    "id": "a1b7a99923349056",
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## 2. 使用命令行开始微调,我们使用 lora 进行微调\n",
    "接着，我们仅需要将配置好的参数以命令行的形式传参给程序，就可以使用命令行进行高效微调。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17c87410a24d844f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "17c87410a24d844f",
    "outputId": "e347fc7d-875e-40c9-c682-3e064100476b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:03<00:00,  1.85it/s]\n",
      "trainable params: 1,949,696 || all params: 6,245,533,696 || trainable%: 0.0312\n",
      "--> Model\n",
      "\n",
      "--> model has 1.949696M params\n",
      "\n",
      "Setting num_proc from 16 back to 1 for the train split to disable multiprocessing as it only contains one shard.\n",
      "Generating train split: 114599 examples [00:00, 1390855.71 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the validation split to disable multiprocessing as it only contains one shard.\n",
      "Generating validation split: 1070 examples [00:00, 790124.17 examples/s]\n",
      "Setting num_proc from 16 back to 1 for the test split to disable multiprocessing as it only contains one shard.\n",
      "Generating test split: 1070 examples [00:00, 854839.10 examples/s]\n",
      "Map (num_proc=16): 100%|█████| 114599/114599 [00:01<00:00, 102942.44 examples/s]\n",
      "train_dataset: Dataset({\n",
      "    features: ['input_ids', 'labels'],\n",
      "    num_rows: 114599\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 3184.80 examples/s]\n",
      "val_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "Map (num_proc=16): 100%|███████████| 1070/1070 [00:00<00:00, 3232.54 examples/s]\n",
      "test_dataset: Dataset({\n",
      "    features: ['input_ids', 'output_ids'],\n",
      "    num_rows: 1070\n",
      "})\n",
      "--> Sanity check\n",
      "           '[gMASK]': 64790 -> -100\n",
      "               'sop': 64792 -> -100\n",
      "          '<|user|>': 64795 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '\\n': 13 -> -100\n",
      "                  '': 30910 -> -100\n",
      "                '类型': 33467 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '版': 55090 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '宽松': 40833 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '风格': 32799 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '性感': 40589 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                '图案': 37505 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                '线条': 37216 -> -100\n",
      "                 '*': 30998 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "                 '型': 54888 -> -100\n",
      "                 '#': 31010 -> -100\n",
      "                 '阔': 56529 -> -100\n",
      "                 '腿': 56158 -> -100\n",
      "                 '裤': 56532 -> -100\n",
      "     '<|assistant|>': 64796 -> -100\n",
      "                  '': 30910 -> 30910\n",
      "                '\\n': 13 -> 13\n",
      "                  '': 30910 -> 30910\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '阔': 56529 -> 56529\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '这': 54551 -> 54551\n",
      "                '两年': 33808 -> 33808\n",
      "                '真的': 32041 -> 32041\n",
      "                 '吸': 55360 -> 55360\n",
      "                 '粉': 55486 -> 55486\n",
      "                '不少': 32138 -> 32138\n",
      "                 '，': 31123 -> 31123\n",
      "                '明星': 32943 -> 32943\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '达': 54880 -> 54880\n",
      "                '人的': 31664 -> 31664\n",
      "                '心头': 46565 -> 46565\n",
      "                 '爱': 54799 -> 54799\n",
      "                 '。': 31155 -> 31155\n",
      "                '毕竟': 33051 -> 33051\n",
      "                 '好': 54591 -> 54591\n",
      "                 '穿': 55432 -> 55432\n",
      "                '时尚': 33481 -> 33481\n",
      "                 '，': 31123 -> 31123\n",
      "                 '谁': 55622 -> 55622\n",
      "                '都能': 32904 -> 32904\n",
      "                 '穿': 55432 -> 55432\n",
      "                 '出': 54557 -> 54557\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '长': 54625 -> 54625\n",
      "                 '2': 30943 -> 30943\n",
      "                 '米': 55055 -> 55055\n",
      "               '的效果': 35590 -> 35590\n",
      "                '宽松': 40833 -> 40833\n",
      "                 '的': 54530 -> 54530\n",
      "                 '裤': 56532 -> 56532\n",
      "                 '腿': 56158 -> 56158\n",
      "                 '，': 31123 -> 31123\n",
      "               '当然是': 48466 -> 48466\n",
      "                 '遮': 57148 -> 57148\n",
      "                 '肉': 55343 -> 55343\n",
      "                 '小': 54603 -> 54603\n",
      "                '能手': 49355 -> 49355\n",
      "                 '啊': 55674 -> 55674\n",
      "                 '。': 31155 -> 31155\n",
      "                '上身': 51605 -> 51605\n",
      "                 '随': 55119 -> 55119\n",
      "                 '性': 54642 -> 54642\n",
      "                '自然': 31799 -> 31799\n",
      "                 '不': 54535 -> 54535\n",
      "                 '拘': 57036 -> 57036\n",
      "                 '束': 55625 -> 55625\n",
      "                 '，': 31123 -> 31123\n",
      "                '面料': 46839 -> 46839\n",
      "                 '亲': 55113 -> 55113\n",
      "                 '肤': 56089 -> 56089\n",
      "                '舒适': 33894 -> 33894\n",
      "                 '贴': 55778 -> 55778\n",
      "                '身体': 31902 -> 31902\n",
      "                 '验': 55017 -> 55017\n",
      "                 '感': 54706 -> 54706\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '棒': 56382 -> 56382\n",
      "                 '哒': 59230 -> 59230\n",
      "                 '。': 31155 -> 31155\n",
      "                 '系': 54712 -> 54712\n",
      "                 '带': 54882 -> 54882\n",
      "                '部分': 31726 -> 31726\n",
      "                '增加': 31917 -> 31917\n",
      "                '设计': 31735 -> 31735\n",
      "                '看点': 45032 -> 45032\n",
      "                 '，': 31123 -> 31123\n",
      "                 '还': 54656 -> 54656\n",
      "                 '让': 54772 -> 54772\n",
      "                '单品': 46539 -> 46539\n",
      "               '的设计': 34481 -> 34481\n",
      "                 '感': 54706 -> 54706\n",
      "                '更强': 43084 -> 43084\n",
      "                 '。': 31155 -> 31155\n",
      "                '腿部': 46799 -> 46799\n",
      "                '线条': 37216 -> 37216\n",
      "                 '若': 55351 -> 55351\n",
      "                 '隐': 55733 -> 55733\n",
      "                 '若': 55351 -> 55351\n",
      "                 '现': 54600 -> 54600\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                '性感': 40589 -> 40589\n",
      "                 '撩': 58521 -> 58521\n",
      "                 '人': 54533 -> 54533\n",
      "                 '。': 31155 -> 31155\n",
      "                '颜色': 33692 -> 33692\n",
      "                 '敲': 57004 -> 57004\n",
      "                '温柔': 34678 -> 34678\n",
      "                 '的': 54530 -> 54530\n",
      "                 '，': 31123 -> 31123\n",
      "                 '与': 54619 -> 54619\n",
      "                '裤子': 44722 -> 44722\n",
      "                '本身': 32754 -> 32754\n",
      "                 '所': 54626 -> 54626\n",
      "                '呈现': 33169 -> 33169\n",
      "               '的风格': 48084 -> 48084\n",
      "                '有点': 33149 -> 33149\n",
      "                 '反': 54955 -> 54955\n",
      "                 '差': 55342 -> 55342\n",
      "                 '萌': 56842 -> 56842\n",
      "                 '。': 31155 -> 31155\n",
      "                  '': 2 -> 2\n",
      "max_steps is given, it will override any value given in num_train_epochs\n",
      "***** Running training *****\n",
      "  Num examples = 114,599\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 5\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 5\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 34,380\n",
      "  Number of trainable parameters = 1,949,696\n",
      "{'loss': 4.0969, 'grad_norm': 3.1475279331207275, 'learning_rate': 4.985456660849331e-05, 'epoch': 0.0}\n",
      "{'loss': 3.6415, 'grad_norm': 4.6406989097595215, 'learning_rate': 4.970913321698662e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5582, 'grad_norm': 5.00098180770874, 'learning_rate': 4.956369982547993e-05, 'epoch': 0.01}\n",
      "{'loss': 3.5426, 'grad_norm': 5.286025047302246, 'learning_rate': 4.9418266433973246e-05, 'epoch': 0.02}\n",
      "{'loss': 3.5089, 'grad_norm': 5.8512187004089355, 'learning_rate': 4.9272833042466556e-05, 'epoch': 0.02}\n",
      "  1%|▌                                    | 500/34380 [05:12<5:19:50,  1.77it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.14s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.61s/it]\u001B[A\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.92s/it]\u001B[ABuilding prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.244 seconds.\n",
      "Prefix dict has been built successfully.\n",
      "                                                                                \n",
      "\u001B[A{'eval_rouge-1': 30.545274, 'eval_rouge-2': 6.493294, 'eval_rouge-l': 23.984523999999997, 'eval_bleu-4': 0.031397846321602904, 'eval_runtime': 25.6535, 'eval_samples_per_second': 1.949, 'eval_steps_per_second': 0.156, 'epoch': 0.02}\n",
      "  1%|▌                                    | 500/34380 [05:37<5:19:50,  1.77it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.92s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4774, 'grad_norm': 5.70848274230957, 'learning_rate': 4.912739965095986e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4719, 'grad_norm': 5.743645668029785, 'learning_rate': 4.898196625945317e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4631, 'grad_norm': 7.316584587097168, 'learning_rate': 4.883653286794648e-05, 'epoch': 0.03}\n",
      "{'loss': 3.4778, 'grad_norm': 6.864858627319336, 'learning_rate': 4.869109947643979e-05, 'epoch': 0.04}\n",
      "{'loss': 3.4096, 'grad_norm': 6.5802178382873535, 'learning_rate': 4.85456660849331e-05, 'epoch': 0.04}\n",
      "  3%|█                                   | 1000/34380 [10:45<5:52:13,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.03s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.30s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.90562, 'eval_rouge-2': 6.414097999999999, 'eval_rouge-l': 23.438138, 'eval_bleu-4': 0.03117460945352759, 'eval_runtime': 17.3155, 'eval_samples_per_second': 2.888, 'eval_steps_per_second': 0.231, 'epoch': 0.04}\n",
      "  3%|█                                   | 1000/34380 [11:02<5:52:13,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.26s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-1000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4264, 'grad_norm': 6.227141857147217, 'learning_rate': 4.8400232693426414e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4006, 'grad_norm': 6.177114009857178, 'learning_rate': 4.8254799301919725e-05, 'epoch': 0.05}\n",
      "{'loss': 3.4497, 'grad_norm': 7.891374588012695, 'learning_rate': 4.8109365910413036e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4457, 'grad_norm': 6.691070556640625, 'learning_rate': 4.796393251890634e-05, 'epoch': 0.06}\n",
      "{'loss': 3.4231, 'grad_norm': 6.115077972412109, 'learning_rate': 4.781849912739965e-05, 'epoch': 0.07}\n",
      "  4%|█▌                                  | 1500/34380 [16:12<5:55:55,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.432631999999998, 'eval_rouge-2': 6.519931999999999, 'eval_rouge-l': 22.736814, 'eval_bleu-4': 0.03160316912579842, 'eval_runtime': 37.8984, 'eval_samples_per_second': 1.319, 'eval_steps_per_second': 0.106, 'epoch': 0.07}\n",
      "  4%|█▌                                  | 1500/34380 [16:49<5:55:55,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.88s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-1500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4085, 'grad_norm': 6.859813690185547, 'learning_rate': 4.767306573589296e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4492, 'grad_norm': 6.923884391784668, 'learning_rate': 4.752763234438627e-05, 'epoch': 0.07}\n",
      "{'loss': 3.4237, 'grad_norm': 6.979555130004883, 'learning_rate': 4.738219895287958e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3863, 'grad_norm': 6.705827713012695, 'learning_rate': 4.7236765561372894e-05, 'epoch': 0.08}\n",
      "{'loss': 3.3951, 'grad_norm': 7.7864460945129395, 'learning_rate': 4.7091332169866205e-05, 'epoch': 0.09}\n",
      "  6%|██                                  | 2000/34380 [21:57<5:50:46,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:23<00:08,  8.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.499977999999995, 'eval_rouge-2': 6.776058000000001, 'eval_rouge-l': 23.491566000000002, 'eval_bleu-4': 0.03159466258619369, 'eval_runtime': 45.4934, 'eval_samples_per_second': 1.099, 'eval_steps_per_second': 0.088, 'epoch': 0.09}\n",
      "  6%|██                                  | 2000/34380 [22:43<5:50:46,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:33<00:00,  8.72s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-2000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4177, 'grad_norm': 6.48070764541626, 'learning_rate': 4.6945898778359516e-05, 'epoch': 0.09}\n",
      "{'loss': 3.4235, 'grad_norm': 7.2512969970703125, 'learning_rate': 4.680046538685282e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3901, 'grad_norm': 7.840146541595459, 'learning_rate': 4.665503199534613e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3685, 'grad_norm': 6.393359661102295, 'learning_rate': 4.650959860383944e-05, 'epoch': 0.1}\n",
      "{'loss': 3.3892, 'grad_norm': 6.363565921783447, 'learning_rate': 4.636416521233275e-05, 'epoch': 0.11}\n",
      "  7%|██▌                                 | 2500/34380 [27:48<5:55:42,  1.49it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.09s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.58s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.322537999999998, 'eval_rouge-2': 7.010930000000001, 'eval_rouge-l': 24.550649999999997, 'eval_bleu-4': 0.033941990455113806, 'eval_runtime': 17.6188, 'eval_samples_per_second': 2.838, 'eval_steps_per_second': 0.227, 'epoch': 0.11}\n",
      "  7%|██▌                                 | 2500/34380 [28:05<5:55:42,  1.49it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.11s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-2500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.4032, 'grad_norm': 7.7735395431518555, 'learning_rate': 4.621873182082606e-05, 'epoch': 0.11}\n",
      "{'loss': 3.378, 'grad_norm': 6.510788440704346, 'learning_rate': 4.6073298429319374e-05, 'epoch': 0.12}\n",
      "{'loss': 3.345, 'grad_norm': 7.00177001953125, 'learning_rate': 4.5927865037812685e-05, 'epoch': 0.12}\n",
      "{'loss': 3.3518, 'grad_norm': 7.758155345916748, 'learning_rate': 4.5782431646305995e-05, 'epoch': 0.13}\n",
      "{'loss': 3.3423, 'grad_norm': 6.896430492401123, 'learning_rate': 4.56369982547993e-05, 'epoch': 0.13}\n",
      "  9%|███▏                                | 3000/34380 [33:12<5:24:02,  1.61it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.25s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.68s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.780934000000002, 'eval_rouge-2': 6.548525999999999, 'eval_rouge-l': 23.960131999999998, 'eval_bleu-4': 0.033512260467862175, 'eval_runtime': 35.8926, 'eval_samples_per_second': 1.393, 'eval_steps_per_second': 0.111, 'epoch': 0.13}\n",
      "  9%|███▏                                | 3000/34380 [33:48<5:24:02,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:23<00:00,  6.96s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-3000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3538, 'grad_norm': 7.053001403808594, 'learning_rate': 4.549156486329261e-05, 'epoch': 0.14}\n",
      "{'loss': 3.4107, 'grad_norm': 7.885371685028076, 'learning_rate': 4.534613147178592e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3564, 'grad_norm': 7.558918476104736, 'learning_rate': 4.520069808027924e-05, 'epoch': 0.14}\n",
      "{'loss': 3.3812, 'grad_norm': 6.6915717124938965, 'learning_rate': 4.505526468877254e-05, 'epoch': 0.15}\n",
      "{'loss': 3.3216, 'grad_norm': 6.962491512298584, 'learning_rate': 4.490983129726585e-05, 'epoch': 0.15}\n",
      " 10%|███▋                                | 3500/34380 [38:57<5:24:49,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.01it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.447048, 'eval_rouge-2': 7.379569999999998, 'eval_rouge-l': 25.694214, 'eval_bleu-4': 0.03759904625578144, 'eval_runtime': 8.058, 'eval_samples_per_second': 6.205, 'eval_steps_per_second': 0.496, 'epoch': 0.15}\n",
      " 10%|███▋                                | 3500/34380 [39:05<5:24:49,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-3500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3385, 'grad_norm': 7.182916164398193, 'learning_rate': 4.4764397905759164e-05, 'epoch': 0.16}\n",
      "{'loss': 3.3413, 'grad_norm': 6.399035930633545, 'learning_rate': 4.4618964514252475e-05, 'epoch': 0.16}\n",
      "{'loss': 3.4127, 'grad_norm': 7.515894412994385, 'learning_rate': 4.447353112274578e-05, 'epoch': 0.17}\n",
      "{'loss': 3.3393, 'grad_norm': 7.04632568359375, 'learning_rate': 4.4328097731239097e-05, 'epoch': 0.17}\n",
      "{'loss': 3.3296, 'grad_norm': 7.053627967834473, 'learning_rate': 4.418266433973241e-05, 'epoch': 0.17}\n",
      " 12%|████▏                               | 4000/34380 [44:12<4:58:51,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 30.40091, 'eval_rouge-2': 6.721768, 'eval_rouge-l': 23.909319999999997, 'eval_bleu-4': 0.03180415165858326, 'eval_runtime': 27.6239, 'eval_samples_per_second': 1.81, 'eval_steps_per_second': 0.145, 'epoch': 0.17}\n",
      " 12%|████▏                               | 4000/34380 [44:40<4:58:51,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.93s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-4000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.358, 'grad_norm': 7.17117166519165, 'learning_rate': 4.403723094822572e-05, 'epoch': 0.18}\n",
      "{'loss': 3.3457, 'grad_norm': 6.6608357429504395, 'learning_rate': 4.389179755671902e-05, 'epoch': 0.18}\n",
      "{'loss': 3.2569, 'grad_norm': 7.140801906585693, 'learning_rate': 4.374636416521233e-05, 'epoch': 0.19}\n",
      "{'loss': 3.3231, 'grad_norm': 7.303428649902344, 'learning_rate': 4.3600930773705644e-05, 'epoch': 0.19}\n",
      "{'loss': 3.33, 'grad_norm': 7.528174877166748, 'learning_rate': 4.3455497382198955e-05, 'epoch': 0.2}\n",
      " 13%|████▋                               | 4500/34380 [49:49<5:10:47,  1.60it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.22s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.56832, 'eval_rouge-2': 7.620704000000001, 'eval_rouge-l': 24.859274000000006, 'eval_bleu-4': 0.03435977717681832, 'eval_runtime': 27.1482, 'eval_samples_per_second': 1.842, 'eval_steps_per_second': 0.147, 'epoch': 0.2}\n",
      " 13%|████▋                               | 4500/34380 [50:17<5:10:47,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.01s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-4500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3684, 'grad_norm': 8.099676132202148, 'learning_rate': 4.3310063990692265e-05, 'epoch': 0.2}\n",
      "{'loss': 3.2939, 'grad_norm': 7.195583343505859, 'learning_rate': 4.3164630599185576e-05, 'epoch': 0.21}\n",
      "{'loss': 3.3848, 'grad_norm': 7.436572074890137, 'learning_rate': 4.301919720767889e-05, 'epoch': 0.21}\n",
      "{'loss': 3.303, 'grad_norm': 6.863331317901611, 'learning_rate': 4.28737638161722e-05, 'epoch': 0.21}\n",
      "{'loss': 3.3204, 'grad_norm': 7.849661350250244, 'learning_rate': 4.27283304246655e-05, 'epoch': 0.22}\n",
      " 15%|█████▏                              | 5000/34380 [55:29<5:13:35,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.32s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.71s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.89526, 'eval_rouge-2': 7.302969999999999, 'eval_rouge-l': 25.502540000000003, 'eval_bleu-4': 0.03508118143815924, 'eval_runtime': 18.8049, 'eval_samples_per_second': 2.659, 'eval_steps_per_second': 0.213, 'epoch': 0.22}\n",
      " 15%|█████▏                              | 5000/34380 [55:48<5:13:35,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.94s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-5000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3557, 'grad_norm': 8.059579849243164, 'learning_rate': 4.258289703315881e-05, 'epoch': 0.22}\n",
      "{'loss': 3.3647, 'grad_norm': 7.411378383636475, 'learning_rate': 4.2437463641652123e-05, 'epoch': 0.23}\n",
      "{'loss': 3.3218, 'grad_norm': 7.71036434173584, 'learning_rate': 4.2292030250145434e-05, 'epoch': 0.23}\n",
      "{'loss': 3.3068, 'grad_norm': 8.015463829040527, 'learning_rate': 4.2146596858638745e-05, 'epoch': 0.24}\n",
      "{'loss': 3.3307, 'grad_norm': 7.3191819190979, 'learning_rate': 4.2001163467132056e-05, 'epoch': 0.24}\n",
      " 16%|█████▍                            | 5500/34380 [1:00:56<5:01:18,  1.60it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.41s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.46s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.48360399999999, 'eval_rouge-2': 7.30302, 'eval_rouge-l': 25.980156, 'eval_bleu-4': 0.036502590508074334, 'eval_runtime': 17.908, 'eval_samples_per_second': 2.792, 'eval_steps_per_second': 0.223, 'epoch': 0.24}\n",
      " 16%|█████▍                            | 5500/34380 [1:01:14<5:01:18,  1.60it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.36s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-5500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.306, 'grad_norm': 6.805530548095703, 'learning_rate': 4.185573007562537e-05, 'epoch': 0.24}\n",
      "{'loss': 3.3247, 'grad_norm': 7.566136360168457, 'learning_rate': 4.171029668411868e-05, 'epoch': 0.25}\n",
      "{'loss': 3.2988, 'grad_norm': 7.157711505889893, 'learning_rate': 4.156486329261198e-05, 'epoch': 0.25}\n",
      "{'loss': 3.3133, 'grad_norm': 7.907533168792725, 'learning_rate': 4.141942990110529e-05, 'epoch': 0.26}\n",
      "{'loss': 3.2656, 'grad_norm': 7.6947455406188965, 'learning_rate': 4.12739965095986e-05, 'epoch': 0.26}\n",
      " 17%|█████▉                            | 6000/34380 [1:06:20<4:26:19,  1.78it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.09it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:05,  5.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.632667999999995, 'eval_rouge-2': 7.359028, 'eval_rouge-l': 25.510628, 'eval_bleu-4': 0.034258843271828765, 'eval_runtime': 26.9445, 'eval_samples_per_second': 1.856, 'eval_steps_per_second': 0.148, 'epoch': 0.26}\n",
      " 17%|█████▉                            | 6000/34380 [1:06:47<4:26:19,  1.78it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.76s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-6000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3345, 'grad_norm': 9.086990356445312, 'learning_rate': 4.112856311809192e-05, 'epoch': 0.27}\n",
      "{'loss': 3.3162, 'grad_norm': 7.312833786010742, 'learning_rate': 4.0983129726585225e-05, 'epoch': 0.27}\n",
      "{'loss': 3.3034, 'grad_norm': 7.286571979522705, 'learning_rate': 4.0837696335078535e-05, 'epoch': 0.27}\n",
      "{'loss': 3.2951, 'grad_norm': 7.498257637023926, 'learning_rate': 4.0692262943571846e-05, 'epoch': 0.28}\n",
      "{'loss': 3.2807, 'grad_norm': 7.071794509887695, 'learning_rate': 4.054682955206516e-05, 'epoch': 0.28}\n",
      " 19%|██████▍                           | 6500/34380 [1:11:56<5:09:44,  1.50it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.18s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.293749999999996, 'eval_rouge-2': 7.713886, 'eval_rouge-l': 25.289742, 'eval_bleu-4': 0.038822357001102294, 'eval_runtime': 17.2534, 'eval_samples_per_second': 2.898, 'eval_steps_per_second': 0.232, 'epoch': 0.28}\n",
      " 19%|██████▍                           | 6500/34380 [1:12:13<5:09:44,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  2.98s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-6500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.3177, 'grad_norm': 7.700517654418945, 'learning_rate': 4.040139616055846e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2952, 'grad_norm': 8.31343936920166, 'learning_rate': 4.025596276905177e-05, 'epoch': 0.29}\n",
      "{'loss': 3.2717, 'grad_norm': 7.088015556335449, 'learning_rate': 4.011052937754509e-05, 'epoch': 0.3}\n",
      "{'loss': 3.302, 'grad_norm': 7.2497382164001465, 'learning_rate': 3.99650959860384e-05, 'epoch': 0.3}\n",
      "{'loss': 3.3109, 'grad_norm': 7.947322368621826, 'learning_rate': 3.9819662594531704e-05, 'epoch': 0.31}\n",
      " 20%|██████▉                           | 7000/34380 [1:17:22<5:09:18,  1.48it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:15<00:04,  4.80s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.079766, 'eval_rouge-2': 7.649658, 'eval_rouge-l': 24.71808800000001, 'eval_bleu-4': 0.036443868166969734, 'eval_runtime': 28.95, 'eval_samples_per_second': 1.727, 'eval_steps_per_second': 0.138, 'epoch': 0.31}\n",
      " 20%|██████▉                           | 7000/34380 [1:17:51<5:09:18,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  3.54s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-7000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2931, 'grad_norm': 6.875996112823486, 'learning_rate': 3.9674229203025015e-05, 'epoch': 0.31}\n",
      "{'loss': 3.3073, 'grad_norm': 7.979851245880127, 'learning_rate': 3.9528795811518326e-05, 'epoch': 0.31}\n",
      "{'loss': 3.2831, 'grad_norm': 6.9280219078063965, 'learning_rate': 3.938336242001164e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2536, 'grad_norm': 8.161873817443848, 'learning_rate': 3.923792902850494e-05, 'epoch': 0.32}\n",
      "{'loss': 3.2836, 'grad_norm': 8.608377456665039, 'learning_rate': 3.909249563699826e-05, 'epoch': 0.33}\n",
      " 22%|███████▍                          | 7500/34380 [1:22:59<4:37:39,  1.61it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.43s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.947348, 'eval_rouge-2': 7.437066, 'eval_rouge-l': 23.797674, 'eval_bleu-4': 0.03613610457898476, 'eval_runtime': 27.763, 'eval_samples_per_second': 1.801, 'eval_steps_per_second': 0.144, 'epoch': 0.33}\n",
      " 22%|███████▍                          | 7500/34380 [1:23:26<4:37:39,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.18s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-7500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2393, 'grad_norm': 7.2424397468566895, 'learning_rate': 3.894706224549157e-05, 'epoch': 0.33}\n",
      "{'loss': 3.2987, 'grad_norm': 7.478527545928955, 'learning_rate': 3.880162885398488e-05, 'epoch': 0.34}\n",
      "{'loss': 3.3296, 'grad_norm': 8.44472885131836, 'learning_rate': 3.8656195462478184e-05, 'epoch': 0.34}\n",
      "{'loss': 3.24, 'grad_norm': 7.994296073913574, 'learning_rate': 3.8510762070971495e-05, 'epoch': 0.34}\n",
      "{'loss': 3.2657, 'grad_norm': 7.241217136383057, 'learning_rate': 3.8365328679464806e-05, 'epoch': 0.35}\n",
      " 23%|███████▉                          | 8000/34380 [1:28:34<4:37:40,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.67s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.339976, 'eval_rouge-2': 8.575411999999998, 'eval_rouge-l': 26.102021999999998, 'eval_bleu-4': 0.04083976196766155, 'eval_runtime': 17.4604, 'eval_samples_per_second': 2.864, 'eval_steps_per_second': 0.229, 'epoch': 0.35}\n",
      " 23%|███████▉                          | 8000/34380 [1:28:52<4:37:40,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.00s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-8000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2734, 'grad_norm': 6.688027858734131, 'learning_rate': 3.8219895287958116e-05, 'epoch': 0.35}\n",
      "{'loss': 3.2827, 'grad_norm': 8.485016822814941, 'learning_rate': 3.807446189645143e-05, 'epoch': 0.36}\n",
      "{'loss': 3.2957, 'grad_norm': 7.331892013549805, 'learning_rate': 3.792902850494474e-05, 'epoch': 0.36}\n",
      "{'loss': 3.269, 'grad_norm': 7.471316814422607, 'learning_rate': 3.778359511343805e-05, 'epoch': 0.37}\n",
      "{'loss': 3.2516, 'grad_norm': 8.299535751342773, 'learning_rate': 3.763816172193136e-05, 'epoch': 0.37}\n",
      " 25%|████████▍                         | 8500/34380 [1:33:58<4:10:11,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:23<00:08,  8.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.017022000000004, 'eval_rouge-2': 7.303442, 'eval_rouge-l': 25.373492000000002, 'eval_bleu-4': 0.03704850191875588, 'eval_runtime': 27.9126, 'eval_samples_per_second': 1.791, 'eval_steps_per_second': 0.143, 'epoch': 0.37}\n",
      " 25%|████████▍                         | 8500/34380 [1:34:26<4:10:11,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.74s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-8500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2428, 'grad_norm': 14.002510070800781, 'learning_rate': 3.7492728330424664e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2819, 'grad_norm': 8.786118507385254, 'learning_rate': 3.7347294938917974e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2385, 'grad_norm': 8.338224411010742, 'learning_rate': 3.7201861547411285e-05, 'epoch': 0.38}\n",
      "{'loss': 3.2796, 'grad_norm': 7.6726908683776855, 'learning_rate': 3.7056428155904596e-05, 'epoch': 0.39}\n",
      "{'loss': 3.2467, 'grad_norm': 8.076858520507812, 'learning_rate': 3.691099476439791e-05, 'epoch': 0.39}\n",
      " 26%|████████▉                         | 9000/34380 [1:39:33<4:03:30,  1.74it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.41s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.627082, 'eval_rouge-2': 8.071512, 'eval_rouge-l': 24.953972, 'eval_bleu-4': 0.03904751099834435, 'eval_runtime': 27.8464, 'eval_samples_per_second': 1.796, 'eval_steps_per_second': 0.144, 'epoch': 0.39}\n",
      " 26%|████████▉                         | 9000/34380 [1:40:01<4:03:30,  1.74it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.22s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-9000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2495, 'grad_norm': 8.192225456237793, 'learning_rate': 3.676556137289122e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2522, 'grad_norm': 7.740852355957031, 'learning_rate': 3.662012798138453e-05, 'epoch': 0.4}\n",
      "{'loss': 3.2995, 'grad_norm': 7.210042476654053, 'learning_rate': 3.647469458987784e-05, 'epoch': 0.41}\n",
      "{'loss': 3.2263, 'grad_norm': 7.048435211181641, 'learning_rate': 3.632926119837114e-05, 'epoch': 0.41}\n",
      "{'loss': 3.2644, 'grad_norm': 8.926847457885742, 'learning_rate': 3.6183827806864454e-05, 'epoch': 0.41}\n",
      " 28%|█████████▍                        | 9500/34380 [1:45:08<4:04:31,  1.70it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.35s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.252852000000004, 'eval_rouge-2': 8.014166000000001, 'eval_rouge-l': 25.817768, 'eval_bleu-4': 0.03765545457589648, 'eval_runtime': 17.1249, 'eval_samples_per_second': 2.92, 'eval_steps_per_second': 0.234, 'epoch': 0.41}\n",
      " 28%|█████████▍                        | 9500/34380 [1:45:25<4:04:31,  1.70it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.14s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-9500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.227, 'grad_norm': 9.03271484375, 'learning_rate': 3.6038394415357765e-05, 'epoch': 0.42}\n",
      "{'loss': 3.2168, 'grad_norm': 7.403310298919678, 'learning_rate': 3.589296102385108e-05, 'epoch': 0.42}\n",
      "{'loss': 3.2281, 'grad_norm': 7.414134979248047, 'learning_rate': 3.5747527632344386e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2615, 'grad_norm': 8.332907676696777, 'learning_rate': 3.56020942408377e-05, 'epoch': 0.43}\n",
      "{'loss': 3.2522, 'grad_norm': 7.91865873336792, 'learning_rate': 3.545666084933101e-05, 'epoch': 0.44}\n",
      " 29%|█████████▌                       | 10000/34380 [1:50:33<3:59:32,  1.70it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.26s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.19289, 'eval_rouge-2': 7.7551559999999995, 'eval_rouge-l': 25.360284, 'eval_bleu-4': 0.038967221484228085, 'eval_runtime': 8.1362, 'eval_samples_per_second': 6.145, 'eval_steps_per_second': 0.492, 'epoch': 0.44}\n",
      " 29%|█████████▌                       | 10000/34380 [1:50:41<3:59:32,  1.70it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.32s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-10000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2278, 'grad_norm': 8.02910041809082, 'learning_rate': 3.531122745782432e-05, 'epoch': 0.44}\n",
      "{'loss': 3.2326, 'grad_norm': 8.47148323059082, 'learning_rate': 3.516579406631762e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2372, 'grad_norm': 7.8877644538879395, 'learning_rate': 3.5020360674810934e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2173, 'grad_norm': 8.136540412902832, 'learning_rate': 3.487492728330425e-05, 'epoch': 0.45}\n",
      "{'loss': 3.2204, 'grad_norm': 7.809272289276123, 'learning_rate': 3.472949389179756e-05, 'epoch': 0.46}\n",
      " 31%|██████████                       | 10500/34380 [1:55:49<4:03:44,  1.63it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.28s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.716794, 'eval_rouge-2': 8.246263999999998, 'eval_rouge-l': 25.612718000000005, 'eval_bleu-4': 0.04118469086220514, 'eval_runtime': 17.3887, 'eval_samples_per_second': 2.875, 'eval_steps_per_second': 0.23, 'epoch': 0.46}\n",
      " 31%|██████████                       | 10500/34380 [1:56:06<4:03:44,  1.63it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-10500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2556, 'grad_norm': 7.687073707580566, 'learning_rate': 3.4584060500290866e-05, 'epoch': 0.46}\n",
      "{'loss': 3.2452, 'grad_norm': 7.656728267669678, 'learning_rate': 3.443862710878418e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2481, 'grad_norm': 8.15871810913086, 'learning_rate': 3.429319371727749e-05, 'epoch': 0.47}\n",
      "{'loss': 3.2369, 'grad_norm': 7.223443984985352, 'learning_rate': 3.41477603257708e-05, 'epoch': 0.48}\n",
      "{'loss': 3.2404, 'grad_norm': 7.354916572570801, 'learning_rate': 3.400232693426411e-05, 'epoch': 0.48}\n",
      " 32%|██████████▌                      | 11000/34380 [2:01:16<3:52:54,  1.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.48s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.160562, 'eval_rouge-2': 7.365448, 'eval_rouge-l': 24.249769999999998, 'eval_bleu-4': 0.034532880209735925, 'eval_runtime': 45.523, 'eval_samples_per_second': 1.098, 'eval_steps_per_second': 0.088, 'epoch': 0.48}\n",
      " 32%|██████████▌                      | 11000/34380 [2:02:01<3:52:54,  1.67it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:33<00:00,  8.72s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-11000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2192, 'grad_norm': 7.897989749908447, 'learning_rate': 3.385689354275742e-05, 'epoch': 0.48}\n",
      "{'loss': 3.2676, 'grad_norm': 7.8738837242126465, 'learning_rate': 3.371146015125073e-05, 'epoch': 0.49}\n",
      "{'loss': 3.194, 'grad_norm': 7.765528202056885, 'learning_rate': 3.356602675974404e-05, 'epoch': 0.49}\n",
      "{'loss': 3.1894, 'grad_norm': 8.675558090209961, 'learning_rate': 3.3420593368237346e-05, 'epoch': 0.5}\n",
      "{'loss': 3.24, 'grad_norm': 8.577594757080078, 'learning_rate': 3.3275159976730657e-05, 'epoch': 0.5}\n",
      " 33%|███████████                      | 11500/34380 [2:07:08<3:49:56,  1.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.18s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.63s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.262754, 'eval_rouge-2': 7.542114000000001, 'eval_rouge-l': 25.374668, 'eval_bleu-4': 0.03732514394679549, 'eval_runtime': 27.7748, 'eval_samples_per_second': 1.8, 'eval_steps_per_second': 0.144, 'epoch': 0.5}\n",
      " 33%|███████████                      | 11500/34380 [2:07:36<3:49:56,  1.66it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.96s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-11500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2312, 'grad_norm': 7.266880989074707, 'learning_rate': 3.312972658522397e-05, 'epoch': 0.51}\n",
      "{'loss': 3.2212, 'grad_norm': 9.147693634033203, 'learning_rate': 3.298429319371728e-05, 'epoch': 0.51}\n",
      "{'loss': 3.2266, 'grad_norm': 7.887938022613525, 'learning_rate': 3.283885980221059e-05, 'epoch': 0.51}\n",
      "{'loss': 3.257, 'grad_norm': 8.396478652954102, 'learning_rate': 3.26934264107039e-05, 'epoch': 0.52}\n",
      "{'loss': 3.2494, 'grad_norm': 8.250365257263184, 'learning_rate': 3.254799301919721e-05, 'epoch': 0.52}\n",
      " 35%|███████████▌                     | 12000/34380 [2:12:42<3:42:54,  1.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.420570000000005, 'eval_rouge-2': 7.264151999999999, 'eval_rouge-l': 23.891346, 'eval_bleu-4': 0.03507232927777068, 'eval_runtime': 42.453, 'eval_samples_per_second': 1.178, 'eval_steps_per_second': 0.094, 'epoch': 0.52}\n",
      " 35%|███████████▌                     | 12000/34380 [2:13:24<3:42:54,  1.67it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:30<00:00,  7.57s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-12000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2133, 'grad_norm': 7.856858730316162, 'learning_rate': 3.240255962769052e-05, 'epoch': 0.53}\n",
      "{'loss': 3.2013, 'grad_norm': 8.406203269958496, 'learning_rate': 3.2257126236183825e-05, 'epoch': 0.53}\n",
      "{'loss': 3.2163, 'grad_norm': 7.695734977722168, 'learning_rate': 3.2111692844677136e-05, 'epoch': 0.54}\n",
      "{'loss': 3.2612, 'grad_norm': 7.699513912200928, 'learning_rate': 3.196625945317045e-05, 'epoch': 0.54}\n",
      "{'loss': 3.2117, 'grad_norm': 7.580023288726807, 'learning_rate': 3.182082606166376e-05, 'epoch': 0.55}\n",
      " 36%|███████████▉                     | 12500/34380 [2:18:31<3:56:20,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.41s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.097064, 'eval_rouge-2': 7.6799159999999995, 'eval_rouge-l': 24.623709999999996, 'eval_bleu-4': 0.03603487446098161, 'eval_runtime': 27.5348, 'eval_samples_per_second': 1.816, 'eval_steps_per_second': 0.145, 'epoch': 0.55}\n",
      " 36%|███████████▉                     | 12500/34380 [2:18:58<3:56:20,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.11s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-12500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2298, 'grad_norm': 8.184666633605957, 'learning_rate': 3.167539267015707e-05, 'epoch': 0.55}\n",
      "{'loss': 3.2325, 'grad_norm': 8.208179473876953, 'learning_rate': 3.152995927865038e-05, 'epoch': 0.55}\n",
      "{'loss': 3.2353, 'grad_norm': 8.261805534362793, 'learning_rate': 3.138452588714369e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1807, 'grad_norm': 7.906728267669678, 'learning_rate': 3.1239092495637e-05, 'epoch': 0.56}\n",
      "{'loss': 3.1337, 'grad_norm': 7.95728063583374, 'learning_rate': 3.1093659104130305e-05, 'epoch': 0.57}\n",
      " 38%|████████████▍                    | 13000/34380 [2:24:07<3:13:14,  1.84it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:24<00:08,  8.49s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.054128, 'eval_rouge-2': 7.180846, 'eval_rouge-l': 24.290283999999996, 'eval_bleu-4': 0.0352237127949355, 'eval_runtime': 37.7049, 'eval_samples_per_second': 1.326, 'eval_steps_per_second': 0.106, 'epoch': 0.57}\n",
      " 38%|████████████▍                    | 13000/34380 [2:24:45<3:13:14,  1.84it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  5.80s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-13000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2235, 'grad_norm': 7.853506088256836, 'learning_rate': 3.0948225712623616e-05, 'epoch': 0.57}\n",
      "{'loss': 3.2094, 'grad_norm': 8.098388671875, 'learning_rate': 3.0802792321116933e-05, 'epoch': 0.58}\n",
      "{'loss': 3.1943, 'grad_norm': 7.965043544769287, 'learning_rate': 3.0657358929610244e-05, 'epoch': 0.58}\n",
      "{'loss': 3.2548, 'grad_norm': 8.04645824432373, 'learning_rate': 3.0511925538103548e-05, 'epoch': 0.58}\n",
      "{'loss': 3.2099, 'grad_norm': 8.05189037322998, 'learning_rate': 3.036649214659686e-05, 'epoch': 0.59}\n",
      " 39%|████████████▉                    | 13500/34380 [2:29:54<3:31:45,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.29s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.081428, 'eval_rouge-2': 7.730779999999999, 'eval_rouge-l': 24.257907999999993, 'eval_bleu-4': 0.037740156606998386, 'eval_runtime': 27.9534, 'eval_samples_per_second': 1.789, 'eval_steps_per_second': 0.143, 'epoch': 0.59}\n",
      " 39%|████████████▉                    | 13500/34380 [2:30:22<3:31:45,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.30s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-13500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2639, 'grad_norm': 8.6993408203125, 'learning_rate': 3.022105875509017e-05, 'epoch': 0.59}\n",
      "{'loss': 3.2361, 'grad_norm': 8.278862953186035, 'learning_rate': 3.007562536358348e-05, 'epoch': 0.6}\n",
      "{'loss': 3.1592, 'grad_norm': 8.710832595825195, 'learning_rate': 2.9930191972076788e-05, 'epoch': 0.6}\n",
      "{'loss': 3.2345, 'grad_norm': 8.018457412719727, 'learning_rate': 2.97847585805701e-05, 'epoch': 0.61}\n",
      "{'loss': 3.2538, 'grad_norm': 8.038196563720703, 'learning_rate': 2.963932518906341e-05, 'epoch': 0.61}\n",
      " 41%|█████████████▍                   | 14000/34380 [2:35:28<3:20:57,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.14s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:17<00:05,  5.79s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 31.23013, 'eval_rouge-2': 7.233923999999999, 'eval_rouge-l': 23.327976000000003, 'eval_bleu-4': 0.03490210647954039, 'eval_runtime': 31.4788, 'eval_samples_per_second': 1.588, 'eval_steps_per_second': 0.127, 'epoch': 0.61}\n",
      " 41%|█████████████▍                   | 14000/34380 [2:36:00<3:20:57,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:19<00:00,  4.14s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-14000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1887, 'grad_norm': 8.46654987335205, 'learning_rate': 2.949389179755672e-05, 'epoch': 0.62}\n",
      "{'loss': 3.2024, 'grad_norm': 8.303617477416992, 'learning_rate': 2.9348458406050028e-05, 'epoch': 0.62}\n",
      "{'loss': 3.2547, 'grad_norm': 7.85433292388916, 'learning_rate': 2.920302501454334e-05, 'epoch': 0.62}\n",
      "{'loss': 3.1949, 'grad_norm': 8.302388191223145, 'learning_rate': 2.905759162303665e-05, 'epoch': 0.63}\n",
      "{'loss': 3.2816, 'grad_norm': 7.99123477935791, 'learning_rate': 2.8912158231529964e-05, 'epoch': 0.63}\n",
      " 42%|█████████████▉                   | 14500/34380 [2:41:11<3:23:40,  1.63it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.02it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.54s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.837916, 'eval_rouge-2': 7.3066119999999986, 'eval_rouge-l': 26.323264000000005, 'eval_bleu-4': 0.037687838162514295, 'eval_runtime': 7.9634, 'eval_samples_per_second': 6.279, 'eval_steps_per_second': 0.502, 'epoch': 0.63}\n",
      " 42%|█████████████▉                   | 14500/34380 [2:41:19<3:23:40,  1.63it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.43s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-14500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.242, 'grad_norm': 8.205120086669922, 'learning_rate': 2.8766724840023268e-05, 'epoch': 0.64}\n",
      "{'loss': 3.218, 'grad_norm': 7.927493095397949, 'learning_rate': 2.862129144851658e-05, 'epoch': 0.64}\n",
      "{'loss': 3.2238, 'grad_norm': 8.386119842529297, 'learning_rate': 2.847585805700989e-05, 'epoch': 0.65}\n",
      "{'loss': 3.1925, 'grad_norm': 8.88548755645752, 'learning_rate': 2.8330424665503203e-05, 'epoch': 0.65}\n",
      "{'loss': 3.2156, 'grad_norm': 11.163135528564453, 'learning_rate': 2.8184991273996508e-05, 'epoch': 0.65}\n",
      " 44%|██████████████▍                  | 15000/34380 [2:46:28<3:17:04,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.02it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:05,  5.57s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.128374, 'eval_rouge-2': 7.526382, 'eval_rouge-l': 25.384561999999995, 'eval_bleu-4': 0.03511870934012379, 'eval_runtime': 17.9493, 'eval_samples_per_second': 2.786, 'eval_steps_per_second': 0.223, 'epoch': 0.65}\n",
      " 44%|██████████████▍                  | 15000/34380 [2:46:46<3:17:04,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.02s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-15000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2271, 'grad_norm': 8.120560646057129, 'learning_rate': 2.803955788248982e-05, 'epoch': 0.66}\n",
      "{'loss': 3.1892, 'grad_norm': 8.931718826293945, 'learning_rate': 2.7894124490983133e-05, 'epoch': 0.66}\n",
      "{'loss': 3.1981, 'grad_norm': 9.202682495117188, 'learning_rate': 2.7748691099476443e-05, 'epoch': 0.67}\n",
      "{'loss': 3.2039, 'grad_norm': 10.27122688293457, 'learning_rate': 2.7603257707969747e-05, 'epoch': 0.67}\n",
      "{'loss': 3.1887, 'grad_norm': 7.90279483795166, 'learning_rate': 2.745782431646306e-05, 'epoch': 0.68}\n",
      " 45%|██████████████▉                  | 15500/34380 [2:51:56<3:32:18,  1.48it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.51s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.57s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.0461, 'eval_rouge-2': 7.968854, 'eval_rouge-l': 25.42555999999999, 'eval_bleu-4': 0.039155330126130435, 'eval_runtime': 8.5933, 'eval_samples_per_second': 5.819, 'eval_steps_per_second': 0.465, 'epoch': 0.68}\n",
      " 45%|██████████████▉                  | 15500/34380 [2:52:05<3:32:18,  1.48it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-15500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1737, 'grad_norm': 8.226831436157227, 'learning_rate': 2.7312390924956372e-05, 'epoch': 0.68}\n",
      "{'loss': 3.1809, 'grad_norm': 8.54875659942627, 'learning_rate': 2.7166957533449683e-05, 'epoch': 0.68}\n",
      "{'loss': 3.215, 'grad_norm': 8.798355102539062, 'learning_rate': 2.7021524141942987e-05, 'epoch': 0.69}\n",
      "{'loss': 3.2194, 'grad_norm': 10.0009765625, 'learning_rate': 2.68760907504363e-05, 'epoch': 0.69}\n",
      "{'loss': 3.2089, 'grad_norm': 8.396638870239258, 'learning_rate': 2.6730657358929612e-05, 'epoch': 0.7}\n",
      " 47%|███████████████▎                 | 16000/34380 [2:57:14<2:52:41,  1.77it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.10s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.27s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.815552, 'eval_rouge-2': 7.884902, 'eval_rouge-l': 26.104632000000002, 'eval_bleu-4': 0.03645343272331789, 'eval_runtime': 7.5427, 'eval_samples_per_second': 6.629, 'eval_steps_per_second': 0.53, 'epoch': 0.7}\n",
      " 47%|███████████████▎                 | 16000/34380 [2:57:21<2:52:41,  1.77it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-16000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2074, 'grad_norm': 7.939826965332031, 'learning_rate': 2.6585223967422923e-05, 'epoch': 0.7}\n",
      "{'loss': 3.2142, 'grad_norm': 8.295905113220215, 'learning_rate': 2.643979057591623e-05, 'epoch': 0.71}\n",
      "{'loss': 3.2277, 'grad_norm': 9.386737823486328, 'learning_rate': 2.629435718440954e-05, 'epoch': 0.71}\n",
      "{'loss': 3.1886, 'grad_norm': 8.591979026794434, 'learning_rate': 2.6148923792902852e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1893, 'grad_norm': 8.2844877243042, 'learning_rate': 2.6003490401396163e-05, 'epoch': 0.72}\n",
      " 48%|███████████████▊                 | 16500/34380 [3:02:29<2:59:27,  1.66it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.40s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.711858, 'eval_rouge-2': 7.5392280000000005, 'eval_rouge-l': 24.920029999999997, 'eval_bleu-4': 0.03518998868780937, 'eval_runtime': 17.974, 'eval_samples_per_second': 2.782, 'eval_steps_per_second': 0.223, 'epoch': 0.72}\n",
      " 48%|███████████████▊                 | 16500/34380 [3:02:47<2:59:27,  1.66it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.21s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-16500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.198, 'grad_norm': 8.526716232299805, 'learning_rate': 2.585805700988947e-05, 'epoch': 0.72}\n",
      "{'loss': 3.1995, 'grad_norm': 9.305632591247559, 'learning_rate': 2.571262361838278e-05, 'epoch': 0.73}\n",
      "{'loss': 3.2682, 'grad_norm': 10.463774681091309, 'learning_rate': 2.5567190226876092e-05, 'epoch': 0.73}\n",
      "{'loss': 3.2075, 'grad_norm': 8.53322696685791, 'learning_rate': 2.5421756835369403e-05, 'epoch': 0.74}\n",
      "{'loss': 3.1896, 'grad_norm': 9.296619415283203, 'learning_rate': 2.527632344386271e-05, 'epoch': 0.74}\n",
      " 49%|████████████████▎                | 17000/34380 [3:07:56<3:08:06,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.62s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:06<00:02,  2.21s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.419658, 'eval_rouge-2': 8.099508, 'eval_rouge-l': 25.023402, 'eval_bleu-4': 0.03738613280924512, 'eval_runtime': 19.0214, 'eval_samples_per_second': 2.629, 'eval_steps_per_second': 0.21, 'epoch': 0.74}\n",
      " 49%|████████████████▎                | 17000/34380 [3:08:15<3:08:06,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.79s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-17000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1744, 'grad_norm': 8.19155502319336, 'learning_rate': 2.513089005235602e-05, 'epoch': 0.75}\n",
      "{'loss': 3.2057, 'grad_norm': 9.486016273498535, 'learning_rate': 2.498545666084933e-05, 'epoch': 0.75}\n",
      "{'loss': 3.2262, 'grad_norm': 9.049162864685059, 'learning_rate': 2.4840023269342642e-05, 'epoch': 0.75}\n",
      "{'loss': 3.1759, 'grad_norm': 8.628340721130371, 'learning_rate': 2.4694589877835953e-05, 'epoch': 0.76}\n",
      "{'loss': 3.2052, 'grad_norm': 7.883338928222656, 'learning_rate': 2.454915648632926e-05, 'epoch': 0.76}\n",
      " 51%|████████████████▊                | 17500/34380 [3:13:24<2:50:13,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:04,  4.35s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.621520000000004, 'eval_rouge-2': 8.42445, 'eval_rouge-l': 26.111117999999998, 'eval_bleu-4': 0.041541231941749614, 'eval_runtime': 17.5186, 'eval_samples_per_second': 2.854, 'eval_steps_per_second': 0.228, 'epoch': 0.76}\n",
      " 51%|████████████████▊                | 17500/34380 [3:13:42<2:50:13,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-17500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2201, 'grad_norm': 9.541754722595215, 'learning_rate': 2.440372309482257e-05, 'epoch': 0.77}\n",
      "{'loss': 3.206, 'grad_norm': 8.401947975158691, 'learning_rate': 2.4258289703315882e-05, 'epoch': 0.77}\n",
      "{'loss': 3.1784, 'grad_norm': 8.584676742553711, 'learning_rate': 2.4112856311809193e-05, 'epoch': 0.78}\n",
      "{'loss': 3.2289, 'grad_norm': 8.49845027923584, 'learning_rate': 2.39674229203025e-05, 'epoch': 0.78}\n",
      "{'loss': 3.2015, 'grad_norm': 9.286449432373047, 'learning_rate': 2.382198952879581e-05, 'epoch': 0.79}\n",
      " 52%|█████████████████▎               | 18000/34380 [3:18:50<3:00:05,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.24s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.794266, 'eval_rouge-2': 8.33604, 'eval_rouge-l': 25.600202, 'eval_bleu-4': 0.04154321374093086, 'eval_runtime': 19.4695, 'eval_samples_per_second': 2.568, 'eval_steps_per_second': 0.205, 'epoch': 0.79}\n",
      " 52%|█████████████████▎               | 18000/34380 [3:19:10<3:00:05,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  3.95s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-18000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1651, 'grad_norm': 8.721686363220215, 'learning_rate': 2.3676556137289122e-05, 'epoch': 0.79}\n",
      "{'loss': 3.2067, 'grad_norm': 8.951761245727539, 'learning_rate': 2.3531122745782433e-05, 'epoch': 0.79}\n",
      "{'loss': 3.1853, 'grad_norm': 9.244789123535156, 'learning_rate': 2.338568935427574e-05, 'epoch': 0.8}\n",
      "{'loss': 3.1738, 'grad_norm': 8.647390365600586, 'learning_rate': 2.3240255962769054e-05, 'epoch': 0.8}\n",
      "{'loss': 3.2233, 'grad_norm': 8.365044593811035, 'learning_rate': 2.3094822571262362e-05, 'epoch': 0.81}\n",
      " 54%|█████████████████▊               | 18500/34380 [3:24:17<2:34:06,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.27s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.50s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.409493999999995, 'eval_rouge-2': 6.909212, 'eval_rouge-l': 23.668452000000002, 'eval_bleu-4': 0.03367902708460212, 'eval_runtime': 17.5657, 'eval_samples_per_second': 2.846, 'eval_steps_per_second': 0.228, 'epoch': 0.81}\n",
      " 54%|█████████████████▊               | 18500/34380 [3:24:35<2:34:06,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.24s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-18500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1964, 'grad_norm': 8.897255897521973, 'learning_rate': 2.2949389179755673e-05, 'epoch': 0.81}\n",
      "{'loss': 3.1897, 'grad_norm': 8.19709587097168, 'learning_rate': 2.2803955788248983e-05, 'epoch': 0.82}\n",
      "{'loss': 3.1975, 'grad_norm': 9.125224113464355, 'learning_rate': 2.2658522396742294e-05, 'epoch': 0.82}\n",
      "{'loss': 3.196, 'grad_norm': 8.317977905273438, 'learning_rate': 2.25130890052356e-05, 'epoch': 0.82}\n",
      "{'loss': 3.2265, 'grad_norm': 10.138325691223145, 'learning_rate': 2.2367655613728912e-05, 'epoch': 0.83}\n",
      " 55%|██████████████████▏              | 19000/34380 [3:29:42<2:41:03,  1.59it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:15<00:04,  4.89s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.381767999999994, 'eval_rouge-2': 7.5018899999999995, 'eval_rouge-l': 25.59375, 'eval_bleu-4': 0.03668260419293807, 'eval_runtime': 26.5849, 'eval_samples_per_second': 1.881, 'eval_steps_per_second': 0.15, 'epoch': 0.83}\n",
      " 55%|██████████████████▏              | 19000/34380 [3:30:08<2:41:03,  1.59it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:24<00:00,  6.47s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-19000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1648, 'grad_norm': 9.847461700439453, 'learning_rate': 2.2222222222222223e-05, 'epoch': 0.83}\n",
      "{'loss': 3.1847, 'grad_norm': 9.740543365478516, 'learning_rate': 2.2076788830715534e-05, 'epoch': 0.84}\n",
      "{'loss': 3.1835, 'grad_norm': 9.253098487854004, 'learning_rate': 2.193135543920884e-05, 'epoch': 0.84}\n",
      "{'loss': 3.1876, 'grad_norm': 9.295453071594238, 'learning_rate': 2.1785922047702152e-05, 'epoch': 0.85}\n",
      "{'loss': 3.2003, 'grad_norm': 8.859480857849121, 'learning_rate': 2.1640488656195463e-05, 'epoch': 0.85}\n",
      " 57%|██████████████████▋              | 19500/34380 [3:35:17<2:37:06,  1.58it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.67s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.093372, 'eval_rouge-2': 8.571902, 'eval_rouge-l': 25.915026, 'eval_bleu-4': 0.03904396841335274, 'eval_runtime': 23.8068, 'eval_samples_per_second': 2.1, 'eval_steps_per_second': 0.168, 'epoch': 0.85}\n",
      " 57%|██████████████████▋              | 19500/34380 [3:35:41<2:37:06,  1.58it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  4.03s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-19500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1887, 'grad_norm': 9.0303955078125, 'learning_rate': 2.1495055264688774e-05, 'epoch': 0.86}\n",
      "{'loss': 3.1716, 'grad_norm': 8.33660888671875, 'learning_rate': 2.134962187318208e-05, 'epoch': 0.86}\n",
      "{'loss': 3.1902, 'grad_norm': 8.988593101501465, 'learning_rate': 2.1204188481675396e-05, 'epoch': 0.86}\n",
      "{'loss': 3.2044, 'grad_norm': 9.47887134552002, 'learning_rate': 2.1058755090168703e-05, 'epoch': 0.87}\n",
      "{'loss': 3.1871, 'grad_norm': 8.98503589630127, 'learning_rate': 2.0913321698662014e-05, 'epoch': 0.87}\n",
      " 58%|███████████████████▏             | 20000/34380 [3:40:53<2:22:55,  1.68it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.16s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.194218, 'eval_rouge-2': 7.713316, 'eval_rouge-l': 26.662796, 'eval_bleu-4': 0.038903657416802344, 'eval_runtime': 6.8142, 'eval_samples_per_second': 7.338, 'eval_steps_per_second': 0.587, 'epoch': 0.87}\n",
      " 58%|███████████████████▏             | 20000/34380 [3:40:59<2:22:55,  1.68it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.23s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-20000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1734, 'grad_norm': 9.874920845031738, 'learning_rate': 2.076788830715532e-05, 'epoch': 0.88}\n",
      "{'loss': 3.1635, 'grad_norm': 8.620546340942383, 'learning_rate': 2.0622454915648635e-05, 'epoch': 0.88}\n",
      "{'loss': 3.198, 'grad_norm': 10.318142890930176, 'learning_rate': 2.0477021524141943e-05, 'epoch': 0.89}\n",
      "{'loss': 3.2028, 'grad_norm': 9.123063087463379, 'learning_rate': 2.0331588132635254e-05, 'epoch': 0.89}\n",
      "{'loss': 3.1743, 'grad_norm': 8.644681930541992, 'learning_rate': 2.0186154741128564e-05, 'epoch': 0.89}\n",
      " 60%|███████████████████▋             | 20500/34380 [3:46:11<2:13:35,  1.73it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.63s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.58s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.27088800000001, 'eval_rouge-2': 8.836329999999998, 'eval_rouge-l': 26.493470000000002, 'eval_bleu-4': 0.04382119813024517, 'eval_runtime': 13.6949, 'eval_samples_per_second': 3.651, 'eval_steps_per_second': 0.292, 'epoch': 0.89}\n",
      " 60%|███████████████████▋             | 20500/34380 [3:46:24<2:13:35,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-20500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1893, 'grad_norm': 9.053121566772461, 'learning_rate': 2.0040721349621875e-05, 'epoch': 0.9}\n",
      "{'loss': 3.2062, 'grad_norm': 8.853163719177246, 'learning_rate': 1.9895287958115183e-05, 'epoch': 0.9}\n",
      "{'loss': 3.1743, 'grad_norm': 8.706668853759766, 'learning_rate': 1.9749854566608493e-05, 'epoch': 0.91}\n",
      "{'loss': 3.1766, 'grad_norm': 9.299714088439941, 'learning_rate': 1.9604421175101804e-05, 'epoch': 0.91}\n",
      "{'loss': 3.2095, 'grad_norm': 10.940281867980957, 'learning_rate': 1.9458987783595115e-05, 'epoch': 0.92}\n",
      " 61%|████████████████████▏            | 21000/34380 [3:51:31<2:11:57,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.14s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.887342, 'eval_rouge-2': 7.802402, 'eval_rouge-l': 26.106630000000006, 'eval_bleu-4': 0.03743179942958618, 'eval_runtime': 15.3848, 'eval_samples_per_second': 3.25, 'eval_steps_per_second': 0.26, 'epoch': 0.92}\n",
      " 61%|████████████████████▏            | 21000/34380 [3:51:47<2:11:57,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  4.24s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-21000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.2004, 'grad_norm': 10.442180633544922, 'learning_rate': 1.9313554392088422e-05, 'epoch': 0.92}\n",
      "{'loss': 3.2284, 'grad_norm': 9.282493591308594, 'learning_rate': 1.9168121000581733e-05, 'epoch': 0.92}\n",
      "{'loss': 3.184, 'grad_norm': 9.153033256530762, 'learning_rate': 1.9022687609075044e-05, 'epoch': 0.93}\n",
      "{'loss': 3.1808, 'grad_norm': 11.147210121154785, 'learning_rate': 1.8877254217568355e-05, 'epoch': 0.93}\n",
      "{'loss': 3.1555, 'grad_norm': 8.189934730529785, 'learning_rate': 1.8731820826061662e-05, 'epoch': 0.94}\n",
      " 63%|████████████████████▋            | 21500/34380 [3:56:57<2:07:09,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.97s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.75s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.059211999999995, 'eval_rouge-2': 8.415938, 'eval_rouge-l': 26.308584, 'eval_bleu-4': 0.04018421056184991, 'eval_runtime': 18.6403, 'eval_samples_per_second': 2.682, 'eval_steps_per_second': 0.215, 'epoch': 0.94}\n",
      " 63%|████████████████████▋            | 21500/34380 [3:57:15<2:07:09,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.42s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-21500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1955, 'grad_norm': 9.059236526489258, 'learning_rate': 1.8586387434554976e-05, 'epoch': 0.94}\n",
      "{'loss': 3.1716, 'grad_norm': 8.91242504119873, 'learning_rate': 1.8440954043048284e-05, 'epoch': 0.95}\n",
      "{'loss': 3.1752, 'grad_norm': 9.892066955566406, 'learning_rate': 1.8295520651541595e-05, 'epoch': 0.95}\n",
      "{'loss': 3.1445, 'grad_norm': 9.493873596191406, 'learning_rate': 1.8150087260034902e-05, 'epoch': 0.96}\n",
      "{'loss': 3.1989, 'grad_norm': 9.520758628845215, 'learning_rate': 1.8004653868528216e-05, 'epoch': 0.96}\n",
      " 64%|█████████████████████            | 22000/34380 [4:02:23<1:59:46,  1.72it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.44s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.636808, 'eval_rouge-2': 6.911292, 'eval_rouge-l': 26.026794, 'eval_bleu-4': 0.03594996345736165, 'eval_runtime': 17.5613, 'eval_samples_per_second': 2.847, 'eval_steps_per_second': 0.228, 'epoch': 0.96}\n",
      " 64%|█████████████████████            | 22000/34380 [4:02:40<1:59:46,  1.72it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.27s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-22000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1867, 'grad_norm': 8.339906692504883, 'learning_rate': 1.7859220477021524e-05, 'epoch': 0.96}\n",
      "{'loss': 3.1673, 'grad_norm': 9.474416732788086, 'learning_rate': 1.7713787085514834e-05, 'epoch': 0.97}\n",
      "{'loss': 3.1487, 'grad_norm': 8.717470169067383, 'learning_rate': 1.7568353694008145e-05, 'epoch': 0.97}\n",
      "{'loss': 3.1586, 'grad_norm': 8.677054405212402, 'learning_rate': 1.7422920302501456e-05, 'epoch': 0.98}\n",
      "{'loss': 3.143, 'grad_norm': 8.49153995513916, 'learning_rate': 1.7277486910994763e-05, 'epoch': 0.98}\n",
      " 65%|█████████████████████▌           | 22500/34380 [4:07:52<1:59:39,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.29s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.54s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.916982, 'eval_rouge-2': 7.762822, 'eval_rouge-l': 25.509776000000002, 'eval_bleu-4': 0.03929201280816807, 'eval_runtime': 7.8554, 'eval_samples_per_second': 6.365, 'eval_steps_per_second': 0.509, 'epoch': 0.98}\n",
      " 65%|█████████████████████▌           | 22500/34380 [4:08:00<1:59:39,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.40s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-22500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1803, 'grad_norm': 8.627764701843262, 'learning_rate': 1.7132053519488074e-05, 'epoch': 0.99}\n",
      "{'loss': 3.1719, 'grad_norm': 11.041980743408203, 'learning_rate': 1.6986620127981385e-05, 'epoch': 0.99}\n",
      "{'loss': 3.1999, 'grad_norm': 9.756752014160156, 'learning_rate': 1.6841186736474696e-05, 'epoch': 0.99}\n",
      "{'loss': 3.171, 'grad_norm': 9.105879783630371, 'learning_rate': 1.6695753344968003e-05, 'epoch': 1.0}\n",
      "{'loss': 3.1272, 'grad_norm': 8.607065200805664, 'learning_rate': 1.6550319953461314e-05, 'epoch': 1.0}\n",
      " 67%|██████████████████████           | 23000/34380 [4:13:09<2:06:20,  1.50it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.21s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.47s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.619285999999995, 'eval_rouge-2': 7.528326, 'eval_rouge-l': 25.071652, 'eval_bleu-4': 0.03648899520613289, 'eval_runtime': 17.6531, 'eval_samples_per_second': 2.832, 'eval_steps_per_second': 0.227, 'epoch': 1.0}\n",
      " 67%|██████████████████████           | 23000/34380 [4:13:26<2:06:20,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-23000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1778, 'grad_norm': 11.501176834106445, 'learning_rate': 1.6404886561954625e-05, 'epoch': 1.01}\n",
      "{'loss': 3.1014, 'grad_norm': 11.420047760009766, 'learning_rate': 1.6259453170447936e-05, 'epoch': 1.01}\n",
      "{'loss': 3.1705, 'grad_norm': 11.00725269317627, 'learning_rate': 1.6114019778941243e-05, 'epoch': 1.02}\n",
      "{'loss': 3.1121, 'grad_norm': 9.701531410217285, 'learning_rate': 1.5968586387434557e-05, 'epoch': 1.02}\n",
      "{'loss': 3.1338, 'grad_norm': 9.691447257995605, 'learning_rate': 1.5823152995927865e-05, 'epoch': 1.03}\n",
      " 68%|██████████████████████▌          | 23500/34380 [4:18:43<2:01:01,  1.50it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.48s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.58s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.729991999999996, 'eval_rouge-2': 7.1806399999999995, 'eval_rouge-l': 26.134384, 'eval_bleu-4': 0.03697717132610506, 'eval_runtime': 8.3252, 'eval_samples_per_second': 6.006, 'eval_steps_per_second': 0.48, 'epoch': 1.03}\n",
      " 68%|██████████████████████▌          | 23500/34380 [4:18:51<2:01:01,  1.50it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.37s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-23500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1425, 'grad_norm': 9.039628028869629, 'learning_rate': 1.5677719604421175e-05, 'epoch': 1.03}\n",
      "{'loss': 3.1672, 'grad_norm': 10.049114227294922, 'learning_rate': 1.5532286212914486e-05, 'epoch': 1.03}\n",
      "{'loss': 3.1227, 'grad_norm': 10.039407730102539, 'learning_rate': 1.5386852821407797e-05, 'epoch': 1.04}\n",
      "{'loss': 3.1645, 'grad_norm': 9.925792694091797, 'learning_rate': 1.5241419429901105e-05, 'epoch': 1.04}\n",
      "{'loss': 3.1356, 'grad_norm': 9.81562328338623, 'learning_rate': 1.5095986038394417e-05, 'epoch': 1.05}\n",
      " 70%|███████████████████████          | 24000/34380 [4:24:02<1:45:13,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.31s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.284256, 'eval_rouge-2': 8.06432, 'eval_rouge-l': 25.864935999999997, 'eval_bleu-4': 0.03946983776280764, 'eval_runtime': 16.9268, 'eval_samples_per_second': 2.954, 'eval_steps_per_second': 0.236, 'epoch': 1.05}\n",
      " 70%|███████████████████████          | 24000/34380 [4:24:19<1:45:13,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.07s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-24000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1349, 'grad_norm': 11.064881324768066, 'learning_rate': 1.4950552646887724e-05, 'epoch': 1.05}\n",
      "{'loss': 3.1457, 'grad_norm': 10.23426342010498, 'learning_rate': 1.4805119255381037e-05, 'epoch': 1.06}\n",
      "{'loss': 3.1955, 'grad_norm': 9.419724464416504, 'learning_rate': 1.4659685863874344e-05, 'epoch': 1.06}\n",
      "{'loss': 3.1466, 'grad_norm': 8.40719223022461, 'learning_rate': 1.4514252472367657e-05, 'epoch': 1.06}\n",
      "{'loss': 3.1575, 'grad_norm': 9.344544410705566, 'learning_rate': 1.4368819080860966e-05, 'epoch': 1.07}\n",
      " 71%|███████████████████████▌         | 24500/34380 [4:29:29<1:48:58,  1.51it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:04<00:04,  2.21s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:16<00:06,  6.24s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.575936, 'eval_rouge-2': 7.938990000000001, 'eval_rouge-l': 25.500303999999996, 'eval_bleu-4': 0.03858023322535888, 'eval_runtime': 27.7238, 'eval_samples_per_second': 1.804, 'eval_steps_per_second': 0.144, 'epoch': 1.07}\n",
      " 71%|███████████████████████▌         | 24500/34380 [4:29:57<1:48:58,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:25<00:00,  7.31s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-24500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1404, 'grad_norm': 9.601197242736816, 'learning_rate': 1.4223385689354277e-05, 'epoch': 1.07}\n",
      "{'loss': 3.1317, 'grad_norm': 9.679092407226562, 'learning_rate': 1.4077952297847586e-05, 'epoch': 1.08}\n",
      "{'loss': 3.1505, 'grad_norm': 9.32908821105957, 'learning_rate': 1.3932518906340897e-05, 'epoch': 1.08}\n",
      "{'loss': 3.1173, 'grad_norm': 11.447206497192383, 'learning_rate': 1.3787085514834206e-05, 'epoch': 1.09}\n",
      "{'loss': 3.139, 'grad_norm': 9.81920051574707, 'learning_rate': 1.3641652123327517e-05, 'epoch': 1.09}\n",
      " 73%|███████████████████████▉         | 25000/34380 [4:35:06<1:30:25,  1.73it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.02s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:05,  5.55s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.391446, 'eval_rouge-2': 7.766861999999999, 'eval_rouge-l': 26.059072, 'eval_bleu-4': 0.03765372626792409, 'eval_runtime': 16.9827, 'eval_samples_per_second': 2.944, 'eval_steps_per_second': 0.236, 'epoch': 1.09}\n",
      " 73%|███████████████████████▉         | 25000/34380 [4:35:23<1:30:25,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.85s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-25000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1812, 'grad_norm': 10.005316734313965, 'learning_rate': 1.3496218731820826e-05, 'epoch': 1.1}\n",
      "{'loss': 3.1712, 'grad_norm': 9.624384880065918, 'learning_rate': 1.3350785340314136e-05, 'epoch': 1.1}\n",
      "{'loss': 3.1151, 'grad_norm': 9.797898292541504, 'learning_rate': 1.3205351948807446e-05, 'epoch': 1.1}\n",
      "{'loss': 3.1309, 'grad_norm': 9.215513229370117, 'learning_rate': 1.3059918557300756e-05, 'epoch': 1.11}\n",
      "{'loss': 3.1927, 'grad_norm': 9.444422721862793, 'learning_rate': 1.2914485165794065e-05, 'epoch': 1.11}\n",
      " 74%|████████████████████████▍        | 25500/34380 [4:40:33<1:27:37,  1.69it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:16<00:05,  5.19s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.945434000000006, 'eval_rouge-2': 7.711155999999999, 'eval_rouge-l': 25.173368, 'eval_bleu-4': 0.03544879816034811, 'eval_runtime': 29.5866, 'eval_samples_per_second': 1.69, 'eval_steps_per_second': 0.135, 'epoch': 1.11}\n",
      " 74%|████████████████████████▍        | 25500/34380 [4:41:03<1:27:37,  1.69it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:17<00:00,  3.66s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-25500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1418, 'grad_norm': 10.090699195861816, 'learning_rate': 1.2769051774287378e-05, 'epoch': 1.12}\n",
      "{'loss': 3.1589, 'grad_norm': 9.862929344177246, 'learning_rate': 1.2623618382780685e-05, 'epoch': 1.12}\n",
      "{'loss': 3.1514, 'grad_norm': 10.778470993041992, 'learning_rate': 1.2478184991273998e-05, 'epoch': 1.13}\n",
      "{'loss': 3.1681, 'grad_norm': 9.437505722045898, 'learning_rate': 1.2332751599767307e-05, 'epoch': 1.13}\n",
      "{'loss': 3.1295, 'grad_norm': 8.846708297729492, 'learning_rate': 1.2187318208260618e-05, 'epoch': 1.13}\n",
      " 76%|████████████████████████▉        | 26000/34380 [4:46:20<1:29:50,  1.55it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.44s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.53s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.782364, 'eval_rouge-2': 7.572869999999999, 'eval_rouge-l': 26.450671999999994, 'eval_bleu-4': 0.03802392310878107, 'eval_runtime': 7.5455, 'eval_samples_per_second': 6.626, 'eval_steps_per_second': 0.53, 'epoch': 1.13}\n",
      " 76%|████████████████████████▉        | 26000/34380 [4:46:28<1:29:50,  1.55it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.38s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-26000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1586, 'grad_norm': 9.815359115600586, 'learning_rate': 1.2041884816753927e-05, 'epoch': 1.14}\n",
      "{'loss': 3.166, 'grad_norm': 10.129549026489258, 'learning_rate': 1.1896451425247238e-05, 'epoch': 1.14}\n",
      "{'loss': 3.1603, 'grad_norm': 9.81931209564209, 'learning_rate': 1.1751018033740547e-05, 'epoch': 1.15}\n",
      "{'loss': 3.1592, 'grad_norm': 12.366113662719727, 'learning_rate': 1.1605584642233858e-05, 'epoch': 1.15}\n",
      "{'loss': 3.1461, 'grad_norm': 9.92140007019043, 'learning_rate': 1.1460151250727168e-05, 'epoch': 1.16}\n",
      " 77%|█████████████████████████▍       | 26500/34380 [4:51:34<1:24:09,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.36s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.51s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.334562, 'eval_rouge-2': 7.865430000000001, 'eval_rouge-l': 26.567885999999998, 'eval_bleu-4': 0.03731869136857349, 'eval_runtime': 15.3894, 'eval_samples_per_second': 3.249, 'eval_steps_per_second': 0.26, 'epoch': 1.16}\n",
      " 77%|█████████████████████████▍       | 26500/34380 [4:51:49<1:24:09,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  4.35s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-26500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1776, 'grad_norm': 8.963644981384277, 'learning_rate': 1.1314717859220478e-05, 'epoch': 1.16}\n",
      "{'loss': 3.1707, 'grad_norm': 10.109374046325684, 'learning_rate': 1.1169284467713788e-05, 'epoch': 1.16}\n",
      "{'loss': 3.1914, 'grad_norm': 9.303648948669434, 'learning_rate': 1.1023851076207097e-05, 'epoch': 1.17}\n",
      "{'loss': 3.1321, 'grad_norm': 9.981646537780762, 'learning_rate': 1.0878417684700408e-05, 'epoch': 1.17}\n",
      "{'loss': 3.1555, 'grad_norm': 9.903374671936035, 'learning_rate': 1.0732984293193717e-05, 'epoch': 1.18}\n",
      " 79%|█████████████████████████▉       | 27000/34380 [4:56:57<1:11:54,  1.71it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.55s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.63s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.915138, 'eval_rouge-2': 7.571738000000002, 'eval_rouge-l': 25.637736, 'eval_bleu-4': 0.03801088496237645, 'eval_runtime': 17.0874, 'eval_samples_per_second': 2.926, 'eval_steps_per_second': 0.234, 'epoch': 1.18}\n",
      " 79%|█████████████████████████▉       | 27000/34380 [4:57:14<1:11:54,  1.71it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.50s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-27000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1597, 'grad_norm': 10.871451377868652, 'learning_rate': 1.0587550901687028e-05, 'epoch': 1.18}\n",
      "{'loss': 3.1359, 'grad_norm': 11.363072395324707, 'learning_rate': 1.0442117510180339e-05, 'epoch': 1.19}\n",
      "{'loss': 3.1516, 'grad_norm': 10.225354194641113, 'learning_rate': 1.0296684118673648e-05, 'epoch': 1.19}\n",
      "{'loss': 3.1695, 'grad_norm': 9.54193115234375, 'learning_rate': 1.0151250727166959e-05, 'epoch': 1.2}\n",
      "{'loss': 3.1899, 'grad_norm': 9.430377006530762, 'learning_rate': 1.0005817335660268e-05, 'epoch': 1.2}\n",
      " 80%|██████████████████████████▍      | 27500/34380 [5:02:24<1:09:37,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.07s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.20s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.451434000000006, 'eval_rouge-2': 7.598388000000001, 'eval_rouge-l': 25.123442, 'eval_bleu-4': 0.03581288992087937, 'eval_runtime': 23.2787, 'eval_samples_per_second': 2.148, 'eval_steps_per_second': 0.172, 'epoch': 1.2}\n",
      " 80%|██████████████████████████▍      | 27500/34380 [5:02:47<1:09:37,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.03s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-27500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1246, 'grad_norm': 9.935742378234863, 'learning_rate': 9.860383944153579e-06, 'epoch': 1.2}\n",
      "{'loss': 3.1775, 'grad_norm': 10.290094375610352, 'learning_rate': 9.714950552646888e-06, 'epoch': 1.21}\n",
      "{'loss': 3.1628, 'grad_norm': 9.710939407348633, 'learning_rate': 9.569517161140199e-06, 'epoch': 1.21}\n",
      "{'loss': 3.1757, 'grad_norm': 9.876148223876953, 'learning_rate': 9.424083769633508e-06, 'epoch': 1.22}\n",
      "{'loss': 3.1419, 'grad_norm': 10.443401336669922, 'learning_rate': 9.278650378126819e-06, 'epoch': 1.22}\n",
      " 81%|██████████████████████████▉      | 28000/34380 [5:07:57<1:04:41,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.24s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.38s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.351912, 'eval_rouge-2': 7.376956000000002, 'eval_rouge-l': 25.567488000000004, 'eval_bleu-4': 0.03645273926535476, 'eval_runtime': 11.743, 'eval_samples_per_second': 4.258, 'eval_steps_per_second': 0.341, 'epoch': 1.22}\n",
      " 81%|██████████████████████████▉      | 28000/34380 [5:08:09<1:04:41,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.21s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-28000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1326, 'grad_norm': 9.526766777038574, 'learning_rate': 9.13321698662013e-06, 'epoch': 1.23}\n",
      "{'loss': 3.1763, 'grad_norm': 8.92110538482666, 'learning_rate': 8.987783595113439e-06, 'epoch': 1.23}\n",
      "{'loss': 3.1448, 'grad_norm': 9.769050598144531, 'learning_rate': 8.84235020360675e-06, 'epoch': 1.23}\n",
      "{'loss': 3.2051, 'grad_norm': 10.095192909240723, 'learning_rate': 8.696916812100058e-06, 'epoch': 1.24}\n",
      "{'loss': 3.1322, 'grad_norm': 10.927847862243652, 'learning_rate': 8.55148342059337e-06, 'epoch': 1.24}\n",
      " 83%|█████████████████████████████      | 28500/34380 [5:13:18<59:53,  1.64it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:12<00:12,  6.08s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:13<00:04,  4.20s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.766402, 'eval_rouge-2': 7.549531999999999, 'eval_rouge-l': 25.273794000000002, 'eval_bleu-4': 0.03544751538481834, 'eval_runtime': 16.6512, 'eval_samples_per_second': 3.003, 'eval_steps_per_second': 0.24, 'epoch': 1.24}\n",
      " 83%|█████████████████████████████      | 28500/34380 [5:13:35<59:53,  1.64it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:14<00:00,  3.04s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-28500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.113, 'grad_norm': 10.306183815002441, 'learning_rate': 8.406050029086678e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1468, 'grad_norm': 9.629598617553711, 'learning_rate': 8.260616637579989e-06, 'epoch': 1.25}\n",
      "{'loss': 3.1186, 'grad_norm': 9.371172904968262, 'learning_rate': 8.115183246073298e-06, 'epoch': 1.26}\n",
      "{'loss': 3.1305, 'grad_norm': 9.336700439453125, 'learning_rate': 7.969749854566609e-06, 'epoch': 1.26}\n",
      "{'loss': 3.1542, 'grad_norm': 12.013757705688477, 'learning_rate': 7.82431646305992e-06, 'epoch': 1.27}\n",
      " 84%|█████████████████████████████▌     | 29000/34380 [5:18:46<55:19,  1.62it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.04s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.20s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.432096, 'eval_rouge-2': 7.484956000000002, 'eval_rouge-l': 25.452722000000005, 'eval_bleu-4': 0.038217382712147564, 'eval_runtime': 17.4461, 'eval_samples_per_second': 2.866, 'eval_steps_per_second': 0.229, 'epoch': 1.27}\n",
      " 84%|█████████████████████████████▌     | 29000/34380 [5:19:04<55:19,  1.62it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-29000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1559, 'grad_norm': 10.81466007232666, 'learning_rate': 7.678883071553229e-06, 'epoch': 1.27}\n",
      "{'loss': 3.1663, 'grad_norm': 9.08803653717041, 'learning_rate': 7.533449680046539e-06, 'epoch': 1.27}\n",
      "{'loss': 3.1275, 'grad_norm': 11.0302095413208, 'learning_rate': 7.38801628853985e-06, 'epoch': 1.28}\n",
      "{'loss': 3.1853, 'grad_norm': 10.48183536529541, 'learning_rate': 7.24258289703316e-06, 'epoch': 1.28}\n",
      "{'loss': 3.1132, 'grad_norm': 9.83420181274414, 'learning_rate': 7.09714950552647e-06, 'epoch': 1.29}\n",
      " 86%|██████████████████████████████     | 29500/34380 [5:24:12<46:59,  1.73it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.03s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.22s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.202884, 'eval_rouge-2': 7.653122000000001, 'eval_rouge-l': 25.898445999999993, 'eval_bleu-4': 0.03783494704005493, 'eval_runtime': 6.377, 'eval_samples_per_second': 7.841, 'eval_steps_per_second': 0.627, 'epoch': 1.29}\n",
      " 86%|██████████████████████████████     | 29500/34380 [5:24:18<46:59,  1.73it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.13s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-29500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1147, 'grad_norm': 10.067401885986328, 'learning_rate': 6.9517161140197796e-06, 'epoch': 1.29}\n",
      "{'loss': 3.1296, 'grad_norm': 10.998579025268555, 'learning_rate': 6.8062827225130895e-06, 'epoch': 1.3}\n",
      "{'loss': 3.1292, 'grad_norm': 9.621427536010742, 'learning_rate': 6.6608493310063995e-06, 'epoch': 1.3}\n",
      "{'loss': 3.1402, 'grad_norm': 9.697392463684082, 'learning_rate': 6.5154159394997094e-06, 'epoch': 1.3}\n",
      "{'loss': 3.114, 'grad_norm': 10.347485542297363, 'learning_rate': 6.369982547993019e-06, 'epoch': 1.31}\n",
      " 87%|██████████████████████████████▌    | 30000/34380 [5:29:26<47:56,  1.52it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.29s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.91s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.724712, 'eval_rouge-2': 7.385546000000001, 'eval_rouge-l': 25.645838000000005, 'eval_bleu-4': 0.035870632684802915, 'eval_runtime': 18.495, 'eval_samples_per_second': 2.703, 'eval_steps_per_second': 0.216, 'epoch': 1.31}\n",
      " 87%|██████████████████████████████▌    | 30000/34380 [5:29:45<47:56,  1.52it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.48s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-30000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1425, 'grad_norm': 9.69785213470459, 'learning_rate': 6.22454915648633e-06, 'epoch': 1.31}\n",
      "{'loss': 3.1189, 'grad_norm': 10.906089782714844, 'learning_rate': 6.07911576497964e-06, 'epoch': 1.32}\n",
      "{'loss': 3.1658, 'grad_norm': 10.275089263916016, 'learning_rate': 5.93368237347295e-06, 'epoch': 1.32}\n",
      "{'loss': 3.166, 'grad_norm': 10.361126899719238, 'learning_rate': 5.78824898196626e-06, 'epoch': 1.33}\n",
      "{'loss': 3.1182, 'grad_norm': 11.111418724060059, 'learning_rate': 5.64281559045957e-06, 'epoch': 1.33}\n",
      " 89%|███████████████████████████████    | 30500/34380 [5:34:52<41:53,  1.54it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.59s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.86s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.655012000000006, 'eval_rouge-2': 7.587047999999999, 'eval_rouge-l': 25.679318, 'eval_bleu-4': 0.03770266751337778, 'eval_runtime': 8.7135, 'eval_samples_per_second': 5.738, 'eval_steps_per_second': 0.459, 'epoch': 1.33}\n",
      " 89%|███████████████████████████████    | 30500/34380 [5:35:01<41:53,  1.54it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.63s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-30500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1554, 'grad_norm': 9.820489883422852, 'learning_rate': 5.49738219895288e-06, 'epoch': 1.34}\n",
      "{'loss': 3.1113, 'grad_norm': 10.787487030029297, 'learning_rate': 5.35194880744619e-06, 'epoch': 1.34}\n",
      "{'loss': 3.1683, 'grad_norm': 10.518128395080566, 'learning_rate': 5.2065154159395e-06, 'epoch': 1.34}\n",
      "{'loss': 3.119, 'grad_norm': 10.444401741027832, 'learning_rate': 5.061082024432811e-06, 'epoch': 1.35}\n",
      "{'loss': 3.1605, 'grad_norm': 9.900869369506836, 'learning_rate': 4.915648632926121e-06, 'epoch': 1.35}\n",
      " 90%|███████████████████████████████▌   | 31000/34380 [5:40:08<37:15,  1.51it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.10s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.59s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.2748, 'eval_rouge-2': 7.330506000000001, 'eval_rouge-l': 25.318206, 'eval_bleu-4': 0.03627553150244002, 'eval_runtime': 17.6513, 'eval_samples_per_second': 2.833, 'eval_steps_per_second': 0.227, 'epoch': 1.35}\n",
      " 90%|███████████████████████████████▌   | 31000/34380 [5:40:25<37:15,  1.51it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:15<00:00,  3.92s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-31000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1646, 'grad_norm': 10.429773330688477, 'learning_rate': 4.770215241419431e-06, 'epoch': 1.36}\n",
      "{'loss': 3.1654, 'grad_norm': 9.863712310791016, 'learning_rate': 4.6247818499127406e-06, 'epoch': 1.36}\n",
      "{'loss': 3.1172, 'grad_norm': 10.74647331237793, 'learning_rate': 4.4793484584060505e-06, 'epoch': 1.37}\n",
      "{'loss': 3.1735, 'grad_norm': 10.074335098266602, 'learning_rate': 4.3339150668993605e-06, 'epoch': 1.37}\n",
      "{'loss': 3.1507, 'grad_norm': 10.487956047058105, 'learning_rate': 4.18848167539267e-06, 'epoch': 1.37}\n",
      " 92%|████████████████████████████████   | 31500/34380 [5:45:35<29:00,  1.65it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.49s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:14<00:05,  5.81s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 32.780772, 'eval_rouge-2': 6.4551240000000005, 'eval_rouge-l': 24.572743999999997, 'eval_bleu-4': 0.032950549500842675, 'eval_runtime': 28.6395, 'eval_samples_per_second': 1.746, 'eval_steps_per_second': 0.14, 'epoch': 1.37}\n",
      " 92%|████████████████████████████████   | 31500/34380 [5:46:03<29:00,  1.65it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:16<00:00,  4.17s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-31500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.115, 'grad_norm': 10.906929016113281, 'learning_rate': 4.04304828388598e-06, 'epoch': 1.38}\n",
      "{'loss': 3.1353, 'grad_norm': 10.445676803588867, 'learning_rate': 3.89761489237929e-06, 'epoch': 1.38}\n",
      "{'loss': 3.0944, 'grad_norm': 11.154529571533203, 'learning_rate': 3.7521815008726007e-06, 'epoch': 1.39}\n",
      "{'loss': 3.1412, 'grad_norm': 9.733614921569824, 'learning_rate': 3.6067481093659107e-06, 'epoch': 1.39}\n",
      "{'loss': 3.119, 'grad_norm': 10.776786804199219, 'learning_rate': 3.461314717859221e-06, 'epoch': 1.4}\n",
      " 93%|████████████████████████████████▌  | 32000/34380 [5:51:09<24:33,  1.61it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:09<00:09,  4.57s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:12<00:03,  3.88s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.875118, 'eval_rouge-2': 7.527262, 'eval_rouge-l': 25.7432, 'eval_bleu-4': 0.03483902998476084, 'eval_runtime': 15.0478, 'eval_samples_per_second': 3.323, 'eval_steps_per_second': 0.266, 'epoch': 1.4}\n",
      " 93%|████████████████████████████████▌  | 32000/34380 [5:51:24<24:33,  1.61it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:13<00:00,  2.91s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-32000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.114, 'grad_norm': 10.023058891296387, 'learning_rate': 3.315881326352531e-06, 'epoch': 1.4}\n",
      "{'loss': 3.1663, 'grad_norm': 10.444805145263672, 'learning_rate': 3.170447934845841e-06, 'epoch': 1.4}\n",
      "{'loss': 3.1275, 'grad_norm': 9.67929458618164, 'learning_rate': 3.025014543339151e-06, 'epoch': 1.41}\n",
      "{'loss': 3.1457, 'grad_norm': 10.392138481140137, 'learning_rate': 2.879581151832461e-06, 'epoch': 1.41}\n",
      "{'loss': 3.1742, 'grad_norm': 9.952996253967285, 'learning_rate': 2.734147760325771e-06, 'epoch': 1.42}\n",
      " 95%|█████████████████████████████████  | 32500/34380 [5:56:40<20:05,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.23s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.33s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.269853999999995, 'eval_rouge-2': 7.549944, 'eval_rouge-l': 25.824209999999997, 'eval_bleu-4': 0.037562645703108986, 'eval_runtime': 7.0354, 'eval_samples_per_second': 7.107, 'eval_steps_per_second': 0.569, 'epoch': 1.42}\n",
      " 95%|█████████████████████████████████  | 32500/34380 [5:56:47<20:05,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.28s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-32500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1054, 'grad_norm': 10.938279151916504, 'learning_rate': 2.5887143688190808e-06, 'epoch': 1.42}\n",
      "{'loss': 3.1439, 'grad_norm': 10.936408996582031, 'learning_rate': 2.443280977312391e-06, 'epoch': 1.43}\n",
      "{'loss': 3.1361, 'grad_norm': 10.4638090133667, 'learning_rate': 2.297847585805701e-06, 'epoch': 1.43}\n",
      "{'loss': 3.1694, 'grad_norm': 10.734414100646973, 'learning_rate': 2.152414194299011e-06, 'epoch': 1.44}\n",
      "{'loss': 3.094, 'grad_norm': 11.088478088378906, 'learning_rate': 2.006980802792321e-06, 'epoch': 1.44}\n",
      " 96%|█████████████████████████████████▌ | 33000/34380 [6:01:55<13:48,  1.67it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:03<00:03,  1.83s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:05<00:01,  1.80s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.208358, 'eval_rouge-2': 7.584094, 'eval_rouge-l': 25.885885999999996, 'eval_bleu-4': 0.03735637803842717, 'eval_runtime': 18.7299, 'eval_samples_per_second': 2.67, 'eval_steps_per_second': 0.214, 'epoch': 1.44}\n",
      " 96%|█████████████████████████████████▌ | 33000/34380 [6:02:13<13:48,  1.67it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:06<00:00,  1.48s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-33000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.145, 'grad_norm': 10.291117668151855, 'learning_rate': 1.8615474112856312e-06, 'epoch': 1.44}\n",
      "{'loss': 3.1367, 'grad_norm': 10.353673934936523, 'learning_rate': 1.7161140197789413e-06, 'epoch': 1.45}\n",
      "{'loss': 3.1527, 'grad_norm': 10.58617115020752, 'learning_rate': 1.5706806282722513e-06, 'epoch': 1.45}\n",
      "{'loss': 3.1548, 'grad_norm': 10.93664836883545, 'learning_rate': 1.4252472367655615e-06, 'epoch': 1.46}\n",
      "{'loss': 3.1752, 'grad_norm': 10.429716110229492, 'learning_rate': 1.2798138452588714e-06, 'epoch': 1.46}\n",
      " 97%|██████████████████████████████████ | 33500/34380 [6:07:19<09:23,  1.56it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:01<00:01,  1.02it/s]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:03<00:01,  1.16s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 34.024272, 'eval_rouge-2': 7.909097999999999, 'eval_rouge-l': 26.085804, 'eval_bleu-4': 0.03855216206779577, 'eval_runtime': 6.0083, 'eval_samples_per_second': 8.322, 'eval_steps_per_second': 0.666, 'epoch': 1.46}\n",
      " 97%|██████████████████████████████████ | 33500/34380 [6:07:25<09:23,  1.56it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:04<00:00,  1.10s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-33500\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.1488, 'grad_norm': 10.082915306091309, 'learning_rate': 1.1343804537521814e-06, 'epoch': 1.47}\n",
      "{'loss': 3.144, 'grad_norm': 11.362931251525879, 'learning_rate': 9.889470622454915e-07, 'epoch': 1.47}\n",
      "{'loss': 3.1688, 'grad_norm': 10.324328422546387, 'learning_rate': 8.435136707388016e-07, 'epoch': 1.47}\n",
      "{'loss': 3.1441, 'grad_norm': 11.271061897277832, 'learning_rate': 6.980802792321118e-07, 'epoch': 1.48}\n",
      "{'loss': 3.129, 'grad_norm': 10.298580169677734, 'learning_rate': 5.526468877254218e-07, 'epoch': 1.48}\n",
      " 99%|██████████████████████████████████▌| 34000/34380 [6:12:28<04:02,  1.57it/s]***** Running Evaluation *****\n",
      "  Num examples = 50\n",
      "  Batch size = 16\n",
      "\n",
      "  0%|                                                     | 0/4 [00:00<?, ?it/s]\u001B[A\n",
      " 50%|██████████████████████▌                      | 2/4 [00:02<00:02,  1.38s/it]\u001B[A\n",
      " 75%|█████████████████████████████████▊           | 3/4 [00:04<00:01,  1.52s/it]\u001B[A\n",
      "                                                                                \u001B[A\n",
      "\u001B[A{'eval_rouge-1': 33.752542000000005, 'eval_rouge-2': 7.5296780000000005, 'eval_rouge-l': 25.882006, 'eval_bleu-4': 0.037440682284833576, 'eval_runtime': 18.2784, 'eval_samples_per_second': 2.735, 'eval_steps_per_second': 0.219, 'epoch': 1.48}\n",
      " 99%|██████████████████████████████████▌| 34000/34380 [6:12:46<04:02,  1.57it/s]\n",
      "100%|█████████████████████████████████████████████| 4/4 [00:05<00:00,  1.48s/it]\u001B[A\n",
      "                                                                                \u001B[ASaving model checkpoint to ./output-round2/checkpoint-34000\n",
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "loading configuration file config.json from cache at /home/overman/.cache/huggingface/hub/models--THUDM--chatglm3-6b/snapshots/06c7c873c843814171c51330b69c2e2a68e05178/config.json\n",
      "Model config ChatGLMConfig {\n",
      "  \"_name_or_path\": \"THUDM/chatglm3-6b\",\n",
      "  \"add_bias_linear\": false,\n",
      "  \"add_qkv_bias\": true,\n",
      "  \"apply_query_key_layer_scaling\": true,\n",
      "  \"apply_residual_connection_post_layernorm\": false,\n",
      "  \"architectures\": [\n",
      "    \"ChatGLMModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.0,\n",
      "  \"attention_softmax_in_fp32\": true,\n",
      "  \"auto_map\": {\n",
      "    \"AutoConfig\": \"THUDM/chatglm3-6b--configuration_chatglm.ChatGLMConfig\",\n",
      "    \"AutoModel\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForCausalLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSeq2SeqLM\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForConditionalGeneration\",\n",
      "    \"AutoModelForSequenceClassification\": \"THUDM/chatglm3-6b--modeling_chatglm.ChatGLMForSequenceClassification\"\n",
      "  },\n",
      "  \"bias_dropout_fusion\": true,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"ffn_hidden_size\": 13696,\n",
      "  \"fp32_residual_connection\": false,\n",
      "  \"hidden_dropout\": 0.0,\n",
      "  \"hidden_size\": 4096,\n",
      "  \"kv_channels\": 128,\n",
      "  \"layernorm_epsilon\": 1e-05,\n",
      "  \"model_type\": \"chatglm\",\n",
      "  \"multi_query_attention\": true,\n",
      "  \"multi_query_group_num\": 2,\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_layers\": 28,\n",
      "  \"original_rope\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"padded_vocab_size\": 65024,\n",
      "  \"post_layer_norm\": true,\n",
      "  \"pre_seq_len\": null,\n",
      "  \"prefix_projection\": false,\n",
      "  \"quantization_bit\": 0,\n",
      "  \"rmsnorm\": true,\n",
      "  \"seq_length\": 8192,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.40.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 65024\n",
      "}\n",
      "\n",
      "{'loss': 3.0857, 'grad_norm': 10.675752639770508, 'learning_rate': 4.0721349621873184e-07, 'epoch': 1.49}\n",
      "{'loss': 3.1347, 'grad_norm': 9.38550853729248, 'learning_rate': 2.617801047120419e-07, 'epoch': 1.49}\n",
      "{'loss': 3.118, 'grad_norm': 10.250651359558105, 'learning_rate': 1.1634671320535195e-07, 'epoch': 1.5}\n",
      "100%|███████████████████████████████████| 34380/34380 [6:16:38<00:00,  1.72it/s]\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "{'train_runtime': 22598.5027, 'train_samples_per_second': 7.607, 'train_steps_per_second': 1.521, 'train_loss': 3.226332022160413, 'epoch': 1.5}\n",
      "100%|███████████████████████████████████| 34380/34380 [6:16:38<00:00,  1.52it/s]\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1070\n",
      "  Batch size = 16\n",
      "100%|███████████████████████████████████████████| 67/67 [03:27<00:00,  3.10s/it]\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python finetune_hf.py  data/AdvertiseGen_fix  THUDM/chatglm3-6b  configs/lora.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5060015c24e97ae",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5060015c24e97ae",
    "outputId": "d3f03d0d-46bf-4c74-9b00-dc0160da0e15"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:01<00:00,  5.48it/s]\n",
      "Setting eos_token is not supported, use the default one.\n",
      "Setting pad_token is not supported, use the default one.\n",
      "Setting unk_token is not supported, use the default one.\n",
      "这款连衣裙采用不规则的裙摆设计，轻松打造出时尚的层次感，带来别致的视觉体验。套头拉链的门襟，方便穿脱，穿脱更加方便。百褶拼接的领口，性感迷人，凸显女性魅力。百褶的袖口，修饰手臂曲线，修饰手臂纤细。百褶的裙摆，百褶的层数丰富，轻盈飘逸，行走之间，飘逸灵动。网纱的裙摆，轻盈飘逸，带出浪漫气息。腰间的木耳边装饰，修身显瘦。\n"
     ]
    }
   ],
   "source": [
    "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-34000/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T10:22:22.412779Z",
     "start_time": "2024-07-22T10:22:15.657625Z"
    }
   },
   "cell_type": "code",
   "source": "!CUDA_VISIBLE_DEVICES=0 NCCL_P2P_DISABLE=\"1\" NCCL_IB_DISABLE=\"1\" python inference_hf.py output/checkpoint-500/ --prompt \"类型#裙*版型#显瘦*材质#网纱*风格#性感*裙型#百褶*裙下摆#压褶*裙长#连衣裙*裙衣门襟#拉链*裙衣门襟#套头*裙款式#拼接*裙款式#拉链*裙款式#木耳边*裙款式#抽褶*裙款式#不规则\"",
   "id": "fd701125e60cc1e9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/overman/miniconda3/envs/chatglm/lib/python3.10/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\r\n",
      "  warnings.warn(\r\n",
      "Loading checkpoint shards: 100%|██████████████████| 7/7 [00:01<00:00,  5.67it/s]\r\n",
      "Setting eos_token is not supported, use the default one.\r\n",
      "Setting pad_token is not supported, use the default one.\r\n",
      "Setting unk_token is not supported, use the default one.\r\n",
      "这款连衣裙是款性感的包臀连衣裙，精选优质纯棉面料，触感柔软亲肤，穿着舒适不刺激。而网纱的拼接，让整体更具时尚感，更显青春活力。而裙摆的木耳边装饰，让整体更显气质。而拉链的装饰，更是方便实用。而袖口的不规则设计，更显个性。\r\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-22T13:03:43.891459Z",
     "start_time": "2024-07-22T13:03:43.818227Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "epochs = [0.02, 0.04, 0.07, 0.1, 0.13, 0.16, 0.19, 0.22, 0.26, 0.29, 0.32, 0.35, 0.38, 0.41, 0.45, 0.48, 0.51, 0.54, 0.58, 0.61, 0.64, 0.67, 0.7, 0.74, 0.77, 0.8, 0.83, 0.87, 0.9, 0.93, 0.96, 0.99, 1.03, 1.06, 1.09, 1.12, 1.16, 1.19, 1.22, 1.25, 1.29, 1.32, 1.35, 1.38, 1.42, 1.45, 1.48]\n",
    "\n",
    "rouge_1 = [30.545274, 30.90562, 30.432632, 33.063156, 32.905928, 32.8526, 32.629842, 32.851914, 33.172854, 33.290186, 33.05089, 33.463974, 32.74026, 33.498024, 33.562138, 33.479206, 33.11846, 33.640366, 33.609974, 33.59864, 33.302082, 33.840458, 33.501544, 33.892548, 33.703014, 33.925366, 33.629424, 33.689936, 33.534428, 33.718376, 33.808748, 33.920456, 33.841712, 33.784576, 33.628942, 33.921394, 33.81411, 33.8681, 34.004326, 33.777452, 33.84095, 33.98052, 33.94339, 33.75536, 33.89187, 33.935446, 33.752542]\n",
    "\n",
    "rouge_2 = [6.493294, 6.414098, 6.519932, 7.18573, 7.021152, 7.132914, 6.997162, 7.37077, 7.153266, 7.621336, 7.163582, 7.386136, 7.257528, 7.499584, 7.528214, 7.446986, 7.438784, 7.45353, 7.556992, 7.49762, 7.369766, 7.76466, 7.450398, 7.617546, 7.545998, 7.739288, 7.5737, 7.626966, 7.33872, 7.639386, 7.789578, 7.724292, 7.625366, 7.589372, 7.637768, 7.715382, 7.551762, 7.64322, 7.585352, 7.522816, 7.55681, 7.649188, 7.5851, 7.59498, 7.547922, 7.56998, 7.529678]\n",
    "\n",
    "rouge_l = [23.984524, 23.438138, 22.736814, 25.100126, 25.142392, 25.2631, 24.925792, 25.452806, 25.326284, 25.761908, 25.340775, 25.705012, 25.23583, 25.888076, 25.83213, 25.753925, 25.535948, 25.84405, 25.981374, 25.844914, 25.58185, 26.183784, 25.7259, 26.05924, 25.956816, 26.199724, 25.937008, 26.037606, 25.668404, 26.03469, 26.25103, 26.169966, 26.056482, 25.998402, 26.027034, 26.16504, 25.956508, 26.059866, 26.057232, 25.900264, 25.951862, 26.08501, 25.99629, 25.986202, 25.946598, 26.016956, 25.882006]\n",
    "\n",
    "bleu_4 = [0.0313978463216029, 0.0311746094535276, 0.0316031691257984, 0.0317454604915017, 0.0320855737021205, 0.032412977461145, 0.0326797535761837, 0.0330479625165485, 0.0339907312348091, 0.0341639861457152, 0.0347145202765052, 0.0356954633521293, 0.0352665660345476, 0.035837689651413, 0.0358585196828247, 0.0359158924977685, 0.0357615768606609, 0.0362173154831184, 0.0364369854719463, 0.0367390333805162, 0.0367691594261983, 0.0374553829519436, 0.0373254155573388, 0.0375599533746877, 0.0377380257074797, 0.0379009693129077, 0.0377680554727208, 0.0380844778711873, 0.0377294831841843, 0.0381429043146768, 0.0384694174006116, 0.0383620505851305, 0.038420840938081, 0.0385612771664427, 0.0386711622328767, 0.0389278106510973, 0.0386803274385714, 0.0387957743035923, 0.0389105923481831, 0.0386614346323162, 0.0390449289210173, 0.0393208910687729, 0.0391448581204664, 0.0391930543617299, 0.0393096445187557, 0.0394025146020372, 0.0374406822848336]\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(epochs, rouge_1, label='ROUGE-1')\n",
    "#plt.plot(epochs, rouge_2, label='ROUGE-2')\n",
    "#plt.plot(epochs, rouge_l, label='ROUGE-L')\n",
    "#plt.plot(epochs, bleu_4, label='BLEU-4')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Score')\n",
    "plt.title('Evaluation Metrics vs Epoch')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ],
   "id": "de4ed86bba6e11b8",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "4b3ab0f2bd2e03"
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "V100",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
